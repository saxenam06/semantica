{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medical Literature GraphRAG Pipeline\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates a complete medical literature GraphRAG pipeline: ingest research papers from multiple sources (PubMed, medical journals, research databases), extract findings, build research knowledge graph, generate embeddings, set up hybrid search (vector + KG), and query medical literature using advanced RAG.\n",
        "\n",
        "### Modules Used (20+)\n",
        "\n",
        "- **Ingestion**: FileIngestor, WebIngestor, DBIngestor, FeedIngestor\n",
        "- **Parsing**: DocumentParser, PDFParser, HTMLParser, StructuredDataParser\n",
        "- **Extraction**: NERExtractor, RelationExtractor, TripleExtractor, SemanticAnalyzer\n",
        "- **KG**: GraphBuilder, GraphAnalyzer, ConnectivityAnalyzer\n",
        "- **Embeddings**: EmbeddingGenerator, TextEmbedder\n",
        "- **Vector Store**: VectorStore, HybridSearch\n",
        "- **Context**: ContextRetriever, ContextGraphBuilder\n",
        "- **Reasoning**: InferenceEngine, RuleManager, ExplanationGenerator\n",
        "- **Export**: JSONExporter, RDFExporter, ReportGenerator\n",
        "- **Visualization**: KGVisualizer, AnalyticsVisualizer, TemporalVisualizer\n",
        "\n",
        "### Pipeline\n",
        "\n",
        "**Research Papers â†’ Parse â†’ Extract Findings â†’ Build Research KG â†’ Generate Embeddings â†’ Vector Store â†’ GraphRAG Setup â†’ Q&A â†’ Generate Reports â†’ Visualize**\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Ingest Research Papers from Multiple Sources\n",
        "\n",
        "Ingest research papers from PubMed, medical journals, and research databases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.ingest import FileIngestor, WebIngestor, DBIngestor, FeedIngestor\n",
        "from semantica.parse import DocumentParser, PDFParser, HTMLParser, StructuredDataParser\n",
        "from semantica.semantic_extract import NERExtractor, RelationExtractor, TripleExtractor, SemanticAnalyzer\n",
        "from semantica.kg import GraphBuilder, GraphAnalyzer, ConnectivityAnalyzer\n",
        "from semantica.embeddings import EmbeddingGenerator, TextEmbedder\n",
        "from semantica.vector_store import VectorStore, HybridSearch\n",
        "from semantica.context import ContextRetriever, ContextGraphBuilder\n",
        "from semantica.reasoning import InferenceEngine, RuleManager, ExplanationGenerator\n",
        "from semantica.export import JSONExporter, RDFExporter, ReportGenerator\n",
        "from semantica.visualization import KGVisualizer, AnalyticsVisualizer, TemporalVisualizer\n",
        "import tempfile\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "file_ingestor = FileIngestor()\n",
        "web_ingestor = WebIngestor()\n",
        "db_ingestor = DBIngestor()\n",
        "feed_ingestor = FeedIngestor()\n",
        "\n",
        "document_parser = DocumentParser()\n",
        "pdf_parser = PDFParser()\n",
        "html_parser = HTMLParser()\n",
        "structured_parser = StructuredDataParser()\n",
        "\n",
        "# Real medical literature sources\n",
        "medical_literature_sources = [\n",
        "    \"https://pubmed.ncbi.nlm.nih.gov/\",  # PubMed\n",
        "    \"https://www.ncbi.nlm.nih.gov/pmc/\",  # PubMed Central\n",
        "    \"https://www.biorxiv.org/\",  # BioRxiv\n",
        "    \"https://www.medrxiv.org/\"  # MedRxiv\n",
        "]\n",
        "\n",
        "medical_feeds = [\n",
        "    \"https://www.cdc.gov/rss.xml\",  # CDC Health Alerts\n",
        "    \"https://www.who.int/rss-feeds/news-english.xml\"  # WHO News\n",
        "]\n",
        "\n",
        "# Real database connection for medical literature\n",
        "db_connection_string = \"postgresql://user:password@localhost:5432/medical_literature_db\"\n",
        "db_query = \"SELECT paper_id, title, authors, abstract, publication_date, findings FROM research_papers WHERE publication_date > CURRENT_DATE - INTERVAL '1 year' ORDER BY publication_date DESC\"\n",
        "\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "# Sample research paper data\n",
        "research_paper_file = os.path.join(temp_dir, \"research_paper.json\")\n",
        "paper_data = {\n",
        "    \"paper_id\": \"PMID-2024-001\",\n",
        "    \"title\": \"Novel Treatment Approaches for Type 2 Diabetes\",\n",
        "    \"authors\": [\"Dr. Smith\", \"Dr. Jones\"],\n",
        "    \"abstract\": \"This study investigates novel treatment approaches for Type 2 Diabetes, focusing on combination therapies and lifestyle interventions.\",\n",
        "    \"publication_date\": (datetime.now() - timedelta(days=60)).isoformat(),\n",
        "    \"findings\": [\n",
        "        \"Metformin combined with lifestyle changes shows 30% improvement\",\n",
        "        \"Early intervention reduces complications by 40%\",\n",
        "        \"Personalized treatment plans improve patient outcomes\"\n",
        "    ],\n",
        "    \"keywords\": [\"Type 2 Diabetes\", \"Metformin\", \"Treatment\", \"Lifestyle\"]\n",
        "}\n",
        "\n",
        "with open(research_paper_file, 'w') as f:\n",
        "    json.dump(paper_data, f, indent=2)\n",
        "\n",
        "file_objects = file_ingestor.ingest_file(research_paper_file, read_content=True)\n",
        "parsed_data = structured_parser.parse_json(research_paper_file)\n",
        "\n",
        "# Ingest from medical literature sources\n",
        "literature_web_list = []\n",
        "for source_url in medical_literature_sources[:1]:\n",
        "    try:\n",
        "        web_content = web_ingestor.ingest_url(source_url)\n",
        "        if web_content:\n",
        "            literature_web_list.append(web_content)\n",
        "            print(f\"âœ“ Ingested medical literature source: {web_content.url if hasattr(web_content, 'url') else source_url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš  Medical literature source ingestion for {source_url}: {str(e)[:100]}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Ingestion Summary:\")\n",
        "print(f\"  Research papers: {len([file_objects]) if file_objects else 0}\")\n",
        "print(f\"  Medical literature sources: {len(literature_web_list)}\")\n",
        "print(f\"  Database sources: 1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Extract Findings and Build Research Knowledge Graph\n",
        "\n",
        "Extract findings from research papers and build knowledge graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ner_extractor = NERExtractor()\n",
        "relation_extractor = RelationExtractor()\n",
        "triple_extractor = TripleExtractor()\n",
        "semantic_analyzer = SemanticAnalyzer()\n",
        "\n",
        "research_entities = []\n",
        "research_relationships = []\n",
        "all_documents = []\n",
        "\n",
        "# Extract from research paper data\n",
        "if parsed_data and parsed_data.data:\n",
        "    paper = parsed_data.data if isinstance(parsed_data.data, dict) else parsed_data.data[0] if isinstance(parsed_data.data, list) else {}\n",
        "    \n",
        "    if isinstance(paper, dict):\n",
        "        paper_text = f\"{paper.get('title', '')} {paper.get('abstract', '')}\"\n",
        "        all_documents.append(paper_text)\n",
        "        \n",
        "        research_entities.append({\n",
        "            \"id\": paper.get(\"paper_id\", \"\"),\n",
        "            \"type\": \"Research_Paper\",\n",
        "            \"name\": paper.get(\"title\", \"\"),\n",
        "            \"properties\": {\n",
        "                \"authors\": paper.get(\"authors\", []),\n",
        "                \"publication_date\": paper.get(\"publication_date\", \"\")\n",
        "            }\n",
        "        })\n",
        "        \n",
        "        # Findings\n",
        "        for i, finding in enumerate(paper.get(\"findings\", [])):\n",
        "            research_entities.append({\n",
        "                \"id\": f\"{paper.get('paper_id', '')}_finding_{i}\",\n",
        "                \"type\": \"Finding\",\n",
        "                \"name\": finding,\n",
        "                \"properties\": {}\n",
        "            })\n",
        "            research_relationships.append({\n",
        "                \"source\": paper.get(\"paper_id\", \"\"),\n",
        "                \"target\": f\"{paper.get('paper_id', '')}_finding_{i}\",\n",
        "                \"type\": \"reports\",\n",
        "                \"properties\": {}\n",
        "            })\n",
        "        \n",
        "        # Keywords\n",
        "        for keyword in paper.get(\"keywords\", []):\n",
        "            research_entities.append({\n",
        "                \"id\": keyword,\n",
        "                \"type\": \"Keyword\",\n",
        "                \"name\": keyword,\n",
        "                \"properties\": {}\n",
        "            })\n",
        "            research_relationships.append({\n",
        "                \"source\": paper.get(\"paper_id\", \"\"),\n",
        "                \"target\": keyword,\n",
        "                \"type\": \"has_keyword\",\n",
        "                \"properties\": {}\n",
        "            })\n",
        "\n",
        "builder = GraphBuilder()\n",
        "graph_analyzer = GraphAnalyzer()\n",
        "connectivity_analyzer = ConnectivityAnalyzer()\n",
        "\n",
        "research_kg = builder.build(research_entities, research_relationships)\n",
        "\n",
        "metrics = graph_analyzer.compute_metrics(research_kg)\n",
        "connectivity = connectivity_analyzer.analyze_connectivity(research_kg)\n",
        "\n",
        "print(f\"Extracted {len(research_entities)} research entities\")\n",
        "print(f\"Extracted {len(research_relationships)} relationships\")\n",
        "print(f\"Collected {len(all_documents)} research documents\")\n",
        "print(f\"Built research knowledge graph with {len(research_kg.get('entities', []))} entities\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Generate Embeddings and Setup Vector Store\n",
        "\n",
        "Generate embeddings and setup vector store for GraphRAG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_generator = EmbeddingGenerator()\n",
        "text_embedder = TextEmbedder()\n",
        "vector_store = VectorStore()\n",
        "hybrid_search = HybridSearch()\n",
        "\n",
        "embeddings = embedding_generator.generate(all_documents)\n",
        "\n",
        "metadata = []\n",
        "for i, doc in enumerate(all_documents):\n",
        "    metadata.append({\n",
        "        \"id\": f\"doc_{i}\",\n",
        "        \"text\": doc,\n",
        "        \"source\": \"medical_literature\"\n",
        "    })\n",
        "\n",
        "vector_ids = vector_store.store_vectors(embeddings, metadata)\n",
        "\n",
        "print(f\"Generated embeddings for {len(all_documents)} documents\")\n",
        "print(f\"Stored {len(vector_ids)} vectors in vector store\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Setup GraphRAG and Query Medical Literature\n",
        "\n",
        "Setup hybrid search and query medical literature using GraphRAG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "context_retriever = ContextRetriever(\n",
        "    knowledge_graph=research_kg,\n",
        "    vector_store=vector_store\n",
        ")\n",
        "\n",
        "inference_engine = InferenceEngine()\n",
        "rule_manager = RuleManager()\n",
        "explanation_generator = ExplanationGenerator()\n",
        "\n",
        "# Query examples\n",
        "queries = [\n",
        "    \"What are the latest findings on diabetes treatment?\",\n",
        "    \"Find research on Metformin effectiveness\",\n",
        "    \"What studies show improvement in patient outcomes?\"\n",
        "]\n",
        "\n",
        "query_results = []\n",
        "for query in queries:\n",
        "    query_embedding = text_embedder.embed_text(query)\n",
        "    vector_results = vector_store.search_vectors(query_embedding, k=3)\n",
        "    \n",
        "    context_results = context_retriever.retrieve(\n",
        "        query=query,\n",
        "        top_k=3,\n",
        "        use_graph_expansion=True\n",
        "    )\n",
        "    \n",
        "    query_results.append({\n",
        "        \"query\": query,\n",
        "        \"vector_results\": len(vector_results),\n",
        "        \"context_results\": len(context_results) if context_results else 0\n",
        "    })\n",
        "\n",
        "# Medical research inference rules\n",
        "inference_engine.add_rule(\"IF paper reports finding AND finding mentions improvement THEN positive_outcome\")\n",
        "inference_engine.add_rule(\"IF paper has_keyword Treatment AND paper has_keyword Diabetes THEN treatment_research\")\n",
        "\n",
        "if parsed_data and parsed_data.data:\n",
        "    paper = parsed_data.data if isinstance(parsed_data.data, dict) else parsed_data.data[0] if isinstance(parsed_data.data, list) else {}\n",
        "    if isinstance(paper, dict):\n",
        "        inference_engine.add_fact({\n",
        "            \"paper_id\": paper.get(\"paper_id\", \"\"),\n",
        "            \"keywords\": paper.get(\"keywords\", [])\n",
        "        })\n",
        "\n",
        "research_insights = inference_engine.forward_chain()\n",
        "\n",
        "print(f\"Processed {len(queries)} medical literature queries\")\n",
        "for result in query_results:\n",
        "    print(f\"  Query: '{result['query']}' - Vector: {result['vector_results']}, Context: {result['context_results']}\")\n",
        "print(f\"Generated {len(research_insights)} research insights\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Generate Reports and Visualize\n",
        "\n",
        "Generate medical literature analysis reports and visualize results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quality_assessor = KGQualityAssessor()\n",
        "json_exporter = JSONExporter()\n",
        "rdf_exporter = RDFExporter()\n",
        "report_generator = ReportGenerator()\n",
        "\n",
        "quality_score = quality_assessor.assess_overall_quality(research_kg)\n",
        "\n",
        "json_exporter.export_knowledge_graph(research_kg, os.path.join(temp_dir, \"research_kg.json\"))\n",
        "rdf_exporter.export_knowledge_graph(research_kg, os.path.join(temp_dir, \"research_kg.rdf\"))\n",
        "\n",
        "report_data = {\n",
        "    \"summary\": f\"Medical literature analysis identified {len(research_entities)} entities and {len(research_insights)} insights\",\n",
        "    \"papers_analyzed\": len([e for e in research_entities if e.get(\"type\") == \"Research_Paper\"]),\n",
        "    \"findings\": len([e for e in research_entities if e.get(\"type\") == \"Finding\"]),\n",
        "    \"insights\": len(research_insights),\n",
        "    \"quality_score\": quality_score.get('overall_score', 0)\n",
        "}\n",
        "\n",
        "report = report_generator.generate_report(report_data, format=\"markdown\")\n",
        "\n",
        "kg_visualizer = KGVisualizer()\n",
        "analytics_visualizer = AnalyticsVisualizer()\n",
        "temporal_visualizer = TemporalVisualizer()\n",
        "\n",
        "kg_viz = kg_visualizer.visualize_network(research_kg, output=\"interactive\")\n",
        "analytics_viz = analytics_visualizer.visualize_analytics(research_kg, output=\"interactive\")\n",
        "temporal_viz = temporal_visualizer.visualize_timeline(research_kg, output=\"interactive\")\n",
        "\n",
        "print(\"Generated medical literature analysis report and visualizations\")\n",
        "print(f\"Total modules used: 20+\")\n",
        "print(f\"Pipeline complete: Research Papers â†’ Parse â†’ Extract â†’ Build KG â†’ Embeddings â†’ Vector Store â†’ GraphRAG â†’ Q&A â†’ Reports â†’ Visualize\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
