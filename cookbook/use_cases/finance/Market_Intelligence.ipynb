{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Market Intelligence Pipeline\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates a complete market intelligence pipeline: ingest market data from multiple sources (web APIs, financial feeds, databases), extract market entities, build temporal knowledge graph, analyze trends, and generate market insights.\n",
        "\n",
        "### Modules Used (20+)\n",
        "\n",
        "- **Ingestion**: WebIngestor, FeedIngestor, DBIngestor, FileIngestor, MCPIngestor\n",
        "- **Parsing**: JSONParser, CSVParser, StructuredDataParser, HTMLParser, MCPParser\n",
        "- **Extraction**: NERExtractor, RelationExtractor, EventDetector, SemanticAnalyzer\n",
        "- **KG**: GraphBuilder, TemporalGraphQuery, TemporalPatternDetector, GraphAnalyzer\n",
        "- **Analytics**: CentralityCalculator, CommunityDetector, ConnectivityAnalyzer\n",
        "- **Reasoning**: InferenceEngine, RuleManager, ExplanationGenerator\n",
        "- **Export**: JSONExporter, CSVExporter, RDFExporter, ReportGenerator\n",
        "- **Visualization**: KGVisualizer, TemporalVisualizer, AnalyticsVisualizer\n",
        "\n",
        "### Pipeline\n",
        "\n",
        "**Multiple Market Sources (Web, Feeds, DB, Files, MCP) → Parse Data → Extract Market Entities → Build Temporal KG → Analyze Trends → Generate Insights → Export → Visualize**\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Ingest Market Data from Multiple Sources\n",
        "\n",
        "Ingest market data from web APIs, financial feeds, databases, and files.\n",
        "# market_entities = extractor.extract(market_data)\n",
        "'''\n",
        "\n",
        "## Step 3: Build Temporal Market Knowledge Graph\n",
        "\n",
        "'''\n",
        "# from semantica.kg import GraphBuilder\n",
        "# \n",
        "# builder = GraphBuilder()\n",
        "# market_kg = builder.build(market_entities, relationships, temporal=True)\n",
        "'''\n",
        "\n",
        "## Step 4: Analyze Trends\n",
        "\n",
        "'''\n",
        "# from semantica.kg import TemporalQuery\n",
        "# \n",
        "# temporal_query = TemporalQuery()\n",
        "# \n",
        "# # Analyze market trends over time\n",
        "# trends = temporal_query.analyze_trends(market_kg, time_window=\"1M\")\n",
        "# \n",
        "# # Market research\n",
        "# print(f\"Analyzed trends for {len(market_kg.nodes)} market entities\")\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.ingest import WebIngestor, FeedIngestor, DBIngestor, FileIngestor, MCPIngestor, ingest_mcp\n",
        "from semantica.parse import JSONParser, CSVParser, StructuredDataParser, HTMLParser, MCPParser\n",
        "from semantica.semantic_extract import NERExtractor, RelationExtractor, EventDetector, SemanticAnalyzer\n",
        "from semantica.kg import GraphBuilder, TemporalGraphQuery, TemporalPatternDetector, GraphAnalyzer\n",
        "from semantica.kg import CentralityCalculator, CommunityDetector, ConnectivityAnalyzer\n",
        "from semantica.reasoning import InferenceEngine, RuleManager, ExplanationGenerator\n",
        "from semantica.export import JSONExporter, CSVExporter, RDFExporter, ReportGenerator\n",
        "from semantica.visualization import KGVisualizer, TemporalVisualizer, AnalyticsVisualizer\n",
        "import tempfile\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "web_ingestor = WebIngestor()\n",
        "feed_ingestor = FeedIngestor()\n",
        "db_ingestor = DBIngestor()\n",
        "file_ingestor = FileIngestor()\n",
        "mcp_ingestor = MCPIngestor()\n",
        "\n",
        "json_parser = JSONParser()\n",
        "csv_parser = CSVParser()\n",
        "structured_parser = StructuredDataParser()\n",
        "html_parser = HTMLParser()\n",
        "mcp_parser = MCPParser()\n",
        "\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "# Real-world market data formats\n",
        "market_data_json = os.path.join(temp_dir, \"market_data.json\")\n",
        "market_data = [\n",
        "    {\n",
        "        \"symbol\": \"AAPL\",\n",
        "        \"company\": \"Apple Inc.\",\n",
        "        \"price\": 175.50,\n",
        "        \"change\": 2.30,\n",
        "        \"change_percent\": 1.33,\n",
        "        \"volume\": 45000000,\n",
        "        \"timestamp\": (datetime.now() - timedelta(hours=1)).isoformat(),\n",
        "        \"sector\": \"Technology\"\n",
        "    },\n",
        "    {\n",
        "        \"symbol\": \"MSFT\",\n",
        "        \"company\": \"Microsoft Corporation\",\n",
        "        \"price\": 380.25,\n",
        "        \"change\": -1.50,\n",
        "        \"change_percent\": -0.39,\n",
        "        \"volume\": 28000000,\n",
        "        \"timestamp\": (datetime.now() - timedelta(hours=1)).isoformat(),\n",
        "        \"sector\": \"Technology\"\n",
        "    },\n",
        "    {\n",
        "        \"symbol\": \"GOOGL\",\n",
        "        \"company\": \"Alphabet Inc.\",\n",
        "        \"price\": 142.80,\n",
        "        \"change\": 3.20,\n",
        "        \"change_percent\": 2.29,\n",
        "        \"volume\": 32000000,\n",
        "        \"timestamp\": (datetime.now() - timedelta(minutes=30)).isoformat(),\n",
        "        \"sector\": \"Technology\"\n",
        "    }\n",
        "]\n",
        "\n",
        "with open(market_data_json, 'w') as f:\n",
        "    json.dump(market_data, f, indent=2)\n",
        "\n",
        "# CSV format market data (common in financial data exports)\n",
        "market_data_csv = os.path.join(temp_dir, \"market_data.csv\")\n",
        "csv_content = \"\"\"symbol,company,price,change,volume,timestamp,sector\n",
        "TSLA,Tesla Inc.,245.60,5.40,55000000,2024-01-15T10:00:00,Automotive\n",
        "AMZN,Amazon.com Inc.,155.30,1.20,42000000,2024-01-15T10:00:00,Retail\n",
        "NVDA,NVIDIA Corporation,520.75,12.50,68000000,2024-01-15T10:00:00,Technology\"\"\"\n",
        "\n",
        "with open(market_data_csv, 'w') as f:\n",
        "    f.write(csv_content)\n",
        "\n",
        "# Ingest from files\n",
        "file_objects_json = file_ingestor.ingest_file(market_data_json, read_content=True)\n",
        "file_objects_csv = file_ingestor.ingest_file(market_data_csv, read_content=True)\n",
        "\n",
        "# Parse structured data\n",
        "parsed_json = json_parser.parse(market_data_json)\n",
        "parsed_csv = csv_parser.parse(market_data_csv)\n",
        "\n",
        "# Real financial news feed URLs\n",
        "financial_feeds = [\n",
        "    \"https://feeds.reuters.com/reuters/businessNews\",  # Reuters Business\n",
        "    \"https://feeds.reuters.com/reuters/topNews\",  # Reuters Top News\n",
        "    \"https://rss.cnn.com/rss/money_latest.rss\",  # CNN Money\n",
        "    \"https://feeds.bloomberg.com/markets/news.rss\",  # Bloomberg Markets\n",
        "    \"https://www.ft.com/?format=rss\"  # Financial Times\n",
        "]\n",
        "\n",
        "financial_feed_list = []\n",
        "for feed_url in financial_feeds:\n",
        "    try:\n",
        "        financial_feed = feed_ingestor.ingest_feed(feed_url)\n",
        "        if financial_feed:\n",
        "            financial_feed_list.append(financial_feed)\n",
        "            print(f\"✓ Ingested financial feed: {financial_feed.title if hasattr(financial_feed, 'title') else feed_url}\")\n",
        "            print(f\"  Items: {len(financial_feed.items) if hasattr(financial_feed, 'items') else 0}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Feed ingestion for {feed_url}: {str(e)[:100]}\")\n",
        "\n",
        "# Real financial API endpoints (examples - require API keys)\n",
        "financial_apis = [\n",
        "    \"https://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2024-01-01/2024-01-31\",  # Polygon.io (requires API key)\n",
        "    \"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=AAPL&interval=5min&apikey=demo\",  # Alpha Vantage\n",
        "    \"https://api.github.com/repos/ranaroussi/yfinance\"  # Yahoo Finance API wrapper\n",
        "]\n",
        "\n",
        "web_content_list = []\n",
        "for api_url in financial_apis[:1]:  # Process first API\n",
        "    try:\n",
        "        web_content = web_ingestor.ingest_url(api_url)\n",
        "        if web_content:\n",
        "            web_content_list.append(web_content)\n",
        "            print(f\"✓ Ingested API content: {web_content.url if hasattr(web_content, 'url') else api_url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ API ingestion for {api_url}: {str(e)[:100]}\")\n",
        "\n",
        "# Real database connection for market data\n",
        "db_connection_string = \"postgresql://user:password@localhost:5432/market_data_db\"\n",
        "db_query = \"SELECT symbol, price, volume, timestamp FROM market_data WHERE timestamp > NOW() - INTERVAL '1 day' ORDER BY timestamp DESC\"\n",
        "\n",
        "# Optional: Ingest from MCP server\n",
        "# Users can bring their own financial data MCP server via URL\n",
        "mcp_market_data = []\n",
        "try:\n",
        "    # Connect to financial data MCP server via URL\n",
        "    # Example: http://localhost:8000/mcp or https://api.example.com/financial-mcp\n",
        "    financial_mcp_url = \"http://localhost:8000/mcp\"  # Replace with your MCP server URL\n",
        "    \n",
        "    mcp_ingestor.connect(\n",
        "        \"market_mcp_server\",\n",
        "        url=financial_mcp_url,\n",
        "        headers={\"Authorization\": \"Bearer your_token\"} if \"api.example.com\" in financial_mcp_url else {}\n",
        "    )\n",
        "    \n",
        "    # Ingest market data from MCP server resources or tools\n",
        "    mcp_data = mcp_ingestor.ingest_resources(\n",
        "        \"market_mcp_server\",\n",
        "        resource_uris=[\"resource://market_data/daily\"]\n",
        "    )\n",
        "    mcp_market_data.extend(mcp_data)\n",
        "    \n",
        "    # Or use tool-based ingestion\n",
        "    tool_data = mcp_ingestor.ingest_tool_output(\n",
        "        \"market_mcp_server\",\n",
        "        tool_name=\"get_stock_prices\",\n",
        "        arguments={\"symbols\": [\"AAPL\", \"MSFT\", \"GOOGL\"], \"date\": datetime.now().isoformat()}\n",
        "    )\n",
        "    if tool_data:\n",
        "        mcp_market_data.append(tool_data)\n",
        "    \n",
        "    # Parse MCP responses\n",
        "    for mcp_item in mcp_market_data:\n",
        "        parsed_mcp = mcp_parser.parse_response(mcp_item, response_type=\"json\")\n",
        "        if isinstance(parsed_mcp, dict) and \"stock_prices\" in parsed_mcp:\n",
        "            # Merge MCP data with existing market data\n",
        "            market_data.extend(parsed_mcp.get(\"stock_prices\", []))\n",
        "    \n",
        "    print(f\"✓ Ingested {len(mcp_market_data)} items from MCP server\")\n",
        "    mcp_ingestor.disconnect(\"market_mcp_server\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ MCP ingestion skipped: {e}\")\n",
        "    print(\"  Note: MCP ingestion is optional. You can bring your own MCP server via URL.\")\n",
        "\n",
        "print(f\"Ingested {len([file_objects_json]) if file_objects_json else 0} JSON market data files\")\n",
        "print(f\"Ingested {len([file_objects_csv]) if file_objects_csv else 0} CSV market data files\")\n",
        "print(f\"Parsed {len(parsed_json.data) if parsed_json and parsed_json.data else 0} JSON market entries\")\n",
        "print(f\"Parsed {len(parsed_csv.rows) if parsed_csv else 0} CSV market rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Extract Market Entities and Relationships\n",
        "\n",
        "Extract market entities (companies, stocks, sectors) and relationships from market data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ner_extractor = NERExtractor()\n",
        "relation_extractor = RelationExtractor()\n",
        "event_detector = EventDetector()\n",
        "semantic_analyzer = SemanticAnalyzer()\n",
        "\n",
        "market_entities = []\n",
        "market_relationships = []\n",
        "\n",
        "# Extract from JSON data\n",
        "if parsed_json and parsed_json.data:\n",
        "    for entry in parsed_json.data:\n",
        "        if isinstance(entry, dict):\n",
        "            market_entities.append({\n",
        "                \"id\": entry.get(\"symbol\", \"\"),\n",
        "                \"type\": \"Stock\",\n",
        "                \"name\": entry.get(\"symbol\", \"\"),\n",
        "                \"properties\": {\n",
        "                    \"price\": entry.get(\"price\", 0),\n",
        "                    \"change\": entry.get(\"change\", 0),\n",
        "                    \"change_percent\": entry.get(\"change_percent\", 0),\n",
        "                    \"volume\": entry.get(\"volume\", 0),\n",
        "                    \"timestamp\": entry.get(\"timestamp\", \"\")\n",
        "                }\n",
        "            })\n",
        "            market_entities.append({\n",
        "                \"id\": entry.get(\"company\", \"\"),\n",
        "                \"type\": \"Company\",\n",
        "                \"name\": entry.get(\"company\", \"\"),\n",
        "                \"properties\": {}\n",
        "            })\n",
        "            market_entities.append({\n",
        "                \"id\": entry.get(\"sector\", \"\"),\n",
        "                \"type\": \"Sector\",\n",
        "                \"name\": entry.get(\"sector\", \"\"),\n",
        "                \"properties\": {}\n",
        "            })\n",
        "            \n",
        "            market_relationships.append({\n",
        "                \"source\": entry.get(\"symbol\", \"\"),\n",
        "                \"target\": entry.get(\"company\", \"\"),\n",
        "                \"type\": \"ticker_for\",\n",
        "                \"properties\": {\"timestamp\": entry.get(\"timestamp\", \"\")}\n",
        "            })\n",
        "            market_relationships.append({\n",
        "                \"source\": entry.get(\"company\", \"\"),\n",
        "                \"target\": entry.get(\"sector\", \"\"),\n",
        "                \"type\": \"belongs_to\",\n",
        "                \"properties\": {}\n",
        "            })\n",
        "\n",
        "# Extract from CSV data\n",
        "if parsed_csv and parsed_csv.rows:\n",
        "    for row in parsed_csv.rows:\n",
        "        if isinstance(row, dict):\n",
        "            market_entities.append({\n",
        "                \"id\": row.get(\"symbol\", \"\"),\n",
        "                \"type\": \"Stock\",\n",
        "                \"name\": row.get(\"symbol\", \"\"),\n",
        "                \"properties\": {\n",
        "                    \"price\": float(row.get(\"price\", 0)) if row.get(\"price\") else 0,\n",
        "                    \"change\": float(row.get(\"change\", 0)) if row.get(\"change\") else 0,\n",
        "                    \"volume\": int(row.get(\"volume\", 0)) if row.get(\"volume\") else 0,\n",
        "                    \"timestamp\": row.get(\"timestamp\", \"\")\n",
        "                }\n",
        "            })\n",
        "\n",
        "print(f\"Extracted {len(market_entities)} market entities\")\n",
        "print(f\"Extracted {len(market_relationships)} market relationships\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Build Temporal Market Knowledge Graph\n",
        "\n",
        "Build a temporal knowledge graph from market data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = GraphBuilder()\n",
        "temporal_query = TemporalGraphQuery()\n",
        "temporal_pattern_detector = TemporalPatternDetector()\n",
        "graph_analyzer = GraphAnalyzer()\n",
        "\n",
        "market_kg = builder.build(market_entities, market_relationships)\n",
        "\n",
        "# Analyze graph structure\n",
        "metrics = graph_analyzer.compute_metrics(market_kg)\n",
        "centrality_calculator = CentralityCalculator()\n",
        "community_detector = CommunityDetector()\n",
        "connectivity_analyzer = ConnectivityAnalyzer()\n",
        "\n",
        "centrality_scores = centrality_calculator.calculate_centrality(market_kg, measure=\"degree\")\n",
        "communities = community_detector.detect_communities(market_kg)\n",
        "connectivity = connectivity_analyzer.analyze_connectivity(market_kg)\n",
        "\n",
        "print(f\"Built temporal market knowledge graph\")\n",
        "print(f\"  Entities: {len(market_kg.get('entities', []))}\")\n",
        "print(f\"  Relationships: {len(market_kg.get('relationships', []))}\")\n",
        "print(f\"  Graph density: {metrics.get('density', 0):.3f}\")\n",
        "print(f\"  Communities: {len(communities)}\")\n",
        "print(f\"  Central entities: {len([e for e, score in centrality_scores.items() if score > 0])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Analyze Market Trends\n",
        "\n",
        "Analyze market trends using temporal queries and pattern detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = (datetime.now() - timedelta(days=7)).isoformat()\n",
        "end_time = datetime.now().isoformat()\n",
        "\n",
        "temporal_results = temporal_query.query_time_range(\n",
        "    graph=market_kg,\n",
        "    query=\"Find market movements in the last 7 days\",\n",
        "    start_time=start_time,\n",
        "    end_time=end_time\n",
        ")\n",
        "\n",
        "temporal_patterns = temporal_pattern_detector.detect_temporal_patterns(\n",
        "    market_kg,\n",
        "    pattern_type=\"trend\",\n",
        "    min_frequency=1\n",
        ")\n",
        "\n",
        "inference_engine = InferenceEngine()\n",
        "rule_manager = RuleManager()\n",
        "explanation_generator = ExplanationGenerator()\n",
        "\n",
        "# Market analysis rules\n",
        "inference_engine.add_rule(\"IF change_percent > 2 AND volume > 40000000 THEN strong_momentum\")\n",
        "inference_engine.add_rule(\"IF change_percent < -1 AND volume > 50000000 THEN selling_pressure\")\n",
        "\n",
        "# Add facts from market data\n",
        "for entry in parsed_json.data if parsed_json and parsed_json.data else []:\n",
        "    if isinstance(entry, dict):\n",
        "        inference_engine.add_fact({\n",
        "            \"symbol\": entry.get(\"symbol\", \"\"),\n",
        "            \"change_percent\": entry.get(\"change_percent\", 0),\n",
        "            \"volume\": entry.get(\"volume\", 0)\n",
        "        })\n",
        "\n",
        "market_insights = inference_engine.forward_chain()\n",
        "\n",
        "print(f\"Temporal query returned {len(temporal_results.get('entities', []))} entities\")\n",
        "print(f\"Detected {len(temporal_patterns)} temporal patterns\")\n",
        "print(f\"Generated {len(market_insights)} market insights\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Generate Market Intelligence Reports\n",
        "\n",
        "Generate comprehensive market intelligence reports.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "json_exporter = JSONExporter()\n",
        "csv_exporter = CSVExporter()\n",
        "rdf_exporter = RDFExporter()\n",
        "report_generator = ReportGenerator()\n",
        "\n",
        "json_exporter.export_knowledge_graph(market_kg, os.path.join(temp_dir, \"market_kg.json\"))\n",
        "csv_exporter.export_entities(market_entities, os.path.join(temp_dir, \"market_entities.csv\"))\n",
        "rdf_exporter.export_knowledge_graph(market_kg, os.path.join(temp_dir, \"market_kg.rdf\"))\n",
        "\n",
        "report_data = {\n",
        "    \"summary\": f\"Market intelligence analysis identified {len(market_insights)} insights and {len(temporal_patterns)} trends\",\n",
        "    \"stocks_analyzed\": len(market_entities),\n",
        "    \"patterns\": len(temporal_patterns),\n",
        "    \"insights\": len(market_insights),\n",
        "    \"sectors\": len(set([e.get(\"properties\", {}).get(\"sector\", \"\") for e in market_entities if e.get(\"type\") == \"Stock\"]))\n",
        "}\n",
        "\n",
        "report = report_generator.generate_report(report_data, format=\"markdown\")\n",
        "\n",
        "print(\"Generated market intelligence report\")\n",
        "print(f\"Report length: {len(report)} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Visualize Market Intelligence\n",
        "\n",
        "Visualize market knowledge graph and trends.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kg_visualizer = KGVisualizer()\n",
        "temporal_visualizer = TemporalVisualizer()\n",
        "analytics_visualizer = AnalyticsVisualizer()\n",
        "\n",
        "kg_viz = kg_visualizer.visualize_network(market_kg, output=\"interactive\")\n",
        "temporal_viz = temporal_visualizer.visualize_timeline(market_kg, output=\"interactive\")\n",
        "analytics_viz = analytics_visualizer.visualize_analytics(market_kg, output=\"interactive\")\n",
        "\n",
        "print(\"Generated visualizations for market knowledge graph, temporal trends, and analytics\")\n",
        "print(f\"Total modules used: 20+\")\n",
        "print(f\"Pipeline complete: Multiple Market Sources → Parse → Extract → Temporal KG → Analyze Trends → Generate Insights → Export → Visualize\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
