{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hawksight-AI/semantica/blob/main/cookbook/use_cases/renewable_energy/04_Resource_Optimization.ipynb)\n",
    "\n",
    "# Resource Optimization Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates a complete resource optimization pipeline: ingest resource data from multiple sources (resource databases, monitoring systems, APIs), extract resource entities, build resource knowledge graph, analyze efficiency metrics, and optimize resource allocation.\n",
    "\n",
    "\n",
    "**Documentation**: [API Reference](https://semantica.readthedocs.io/use-cases/)\n",
    "\n",
    "### Modules Used (20+)\n",
    "\n",
    "- **Ingestion**: FileIngestor, WebIngestor, FeedIngestor, StreamIngestor, DBIngestor, RepoIngestor, EmailIngestor, MCPIngestor\n",
    "- **Parsing**: JSONParser, CSVParser, StructuredDataParser\n",
    "- **Extraction**: NERExtractor, RelationExtractor, EventDetector, SemanticAnalyzer\n",
    "- **KG**: GraphBuilder, GraphAnalyzer, CentralityCalculator, CommunityDetector\n",
    "- **Analytics**: ConnectivityAnalyzer, TemporalGraphQuery, TemporalPatternDetector\n",
<<<<<<< Updated upstream
    "- **Reasoning**: InferenceEngine, RuleManager, ExplanationGenerator\n",
<<<<<<< HEAD
    "- **Quality**: KGQualityAssessor, ConflictDetector\n",
=======
    "- **Reasoning**: Reasoner (Legacy), RuleManager, ExplanationGenerator\n",
>>>>>>> Stashed changes
=======
>>>>>>> main
    "- **Export**: JSONExporter, CSVExporter, RDFExporter, ReportGenerator\n",
    "- **Visualization**: KGVisualizer, AnalyticsVisualizer, TemporalVisualizer\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "**Resource Data Sources \u2192 Parse \u2192 Extract Entities \u2192 Build Resource KG \u2192 Analyze Efficiency \u2192 Optimize Allocation \u2192 Generate Reports \u2192 Visualize**\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install Semantica from PyPI:\n",
    "\n",
    "```bash\n",
    "pip install semantica\n",
    "# Or with all optional dependencies:\n",
    "pip install semantica[all]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Ingest Resource Data from Multiple Sources\n",
    "\n",
    "Ingest resource data from resource databases, monitoring systems, and APIs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install semantica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.ingest import FileIngestor, DBIngestor, WebIngestor, FeedIngestor\n",
    "from semantica.parse import JSONParser, CSVParser, StructuredDataParser\n",
    "from semantica.semantic_extract import NERExtractor, RelationExtractor, EventDetector, SemanticAnalyzer\n",
    "from semantica.kg import GraphBuilder, GraphAnalyzer, CentralityCalculator, CommunityDetector\n",
    "from semantica.kg import ConnectivityAnalyzer, TemporalGraphQuery, TemporalPatternDetector\n",
<<<<<<< Updated upstream
    "from semantica.reasoning import InferenceEngine, RuleManager, ExplanationGenerator\n",
<<<<<<< HEAD
    
    "from semantica.conflicts import ConflictDetector\n",
=======
    "# # from semantica.reasoning import InferenceEngine, RuleManager, ExplanationGenerator\n",
>>>>>>> Stashed changes
=======
>>>>>>> main
    "from semantica.export import JSONExporter, CSVExporter, RDFExporter, ReportGenerator\n",
    "from semantica.visualization import KGVisualizer, AnalyticsVisualizer, TemporalVisualizer\n",
    "import tempfile\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "file_ingestor = FileIngestor()\n",
    "db_ingestor = DBIngestor()\n",
    "web_ingestor = WebIngestor()\n",
    "feed_ingestor = FeedIngestor()\n",
    "\n",
    "json_parser = JSONParser()\n",
    "csv_parser = CSVParser()\n",
    "structured_parser = StructuredDataParser()\n",
    "\n",
    "# Real resource monitoring APIs\n",
    "resource_apis = [\n",
    "    \"https://api.eia.gov/v2/electricity/operating-generator-capacity/data/\",  # EIA Capacity Data\n",
    "    \"https://www.energy.gov/data\"  # US Energy Department Resource Data\n",
    "]\n",
    "\n",
    "resource_feeds = [\n",
    "    \"https://www.energy.gov/rss\",  # US Energy Department RSS\n",
    "    \"https://feeds.reuters.com/reuters/businessNews\"  # Reuters Business (resource news)\n",
    "]\n",
    "\n",
    "# Real database connection for resource data\n",
    "db_connection_string = \"postgresql://user:password@localhost:5432/resource_db\"\n",
    "db_query = \"SELECT resource_id, resource_type, capacity, utilization, efficiency, location, timestamp FROM resources WHERE timestamp > NOW() - INTERVAL '24 hours' ORDER BY timestamp DESC\"\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Sample resource data\n",
    "resource_file = os.path.join(temp_dir, \"resource_data.json\")\n",
    "resource_data = [\n",
    "    {\n",
    "        \"resource_id\": \"RES-001\",\n",
    "        \"resource_type\": \"Solar_Farm\",\n",
    "        \"capacity_mw\": 100,\n",
    "        \"utilization_percent\": 75,\n",
    "        \"efficiency_percent\": 85,\n",
    "        \"location\": \"California\",\n",
    "        \"timestamp\": (datetime.now() - timedelta(hours=2)).isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"resource_id\": \"RES-002\",\n",
    "        \"resource_type\": \"Wind_Farm\",\n",
    "        \"capacity_mw\": 150,\n",
    "        \"utilization_percent\": 60,\n",
    "        \"efficiency_percent\": 90,\n",
    "        \"location\": \"Texas\",\n",
    "        \"timestamp\": (datetime.now() - timedelta(hours=1)).isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"resource_id\": \"RES-003\",\n",
    "        \"resource_type\": \"Battery_Storage\",\n",
    "        \"capacity_mw\": 50,\n",
    "        \"utilization_percent\": 90,\n",
    "        \"efficiency_percent\": 95,\n",
    "        \"location\": \"Nevada\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "\n",
    "with open(resource_file, 'w') as f:\n",
    "    json.dump(resource_data, f, indent=2)\n",
    "\n",
    "file_objects = file_ingestor.ingest_file(resource_file, read_content=True)\n",
    "parsed_data = structured_parser.parse_json(resource_file)\n",
    "\n",
    "# Ingest from resource APIs\n",
    "resource_api_list = []\n",
    "for api_url in resource_apis[:1]:\n",
    "    api_content = web_ingestor.ingest_url(api_url)\n",
    "    if api_content:\n",
    "        resource_api_list.append(api_content)\n",
    "        print(f\"  Ingested resource API: {api_url}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Resource Data Ingestion Summary:\")\n",
    "print(f\"  Resource data files: {len([file_objects]) if file_objects else 0}\")\n",
    "print(f\"  Resource APIs: {len(resource_api_list)}\")\n",
    "print(f\"  Database sources: 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Resource Entities and Build Resource Knowledge Graph\n",
    "\n",
    "Extract resource entities and build resource knowledge graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_extractor = NERExtractor()\n",
    "relation_extractor = RelationExtractor()\n",
    "event_detector = EventDetector()\n",
    "semantic_analyzer = SemanticAnalyzer()\n",
    "\n",
    "resource_entities = []\n",
    "resource_relationships = []\n",
    "\n",
    "# Extract from resource data\n",
    "if parsed_data and parsed_data.data:\n",
    "    for entry in parsed_data.data if isinstance(parsed_data.data, list) else [parsed_data.data]:\n",
    "        if isinstance(entry, dict):\n",
    "            resource_id = entry.get(\"resource_id\", \"\")\n",
    "            resource_type = entry.get(\"resource_type\", \"\")\n",
    "            location = entry.get(\"location\", \"\")\n",
    "            \n",
    "            resource_entities.append({\n",
    "                \"id\": resource_id,\n",
    "                \"type\": \"Resource\",\n",
    "                \"name\": resource_id,\n",
    "                \"properties\": {\n",
    "                    \"resource_type\": resource_type,\n",
    "                    \"capacity_mw\": entry.get(\"capacity_mw\", 0),\n",
    "                    \"utilization_percent\": entry.get(\"utilization_percent\", 0),\n",
    "                    \"efficiency_percent\": entry.get(\"efficiency_percent\", 0),\n",
    "                    \"location\": location,\n",
    "                    \"timestamp\": entry.get(\"timestamp\", \"\")\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            resource_entities.append({\n",
    "                \"id\": resource_type,\n",
    "                \"type\": \"Resource_Type\",\n",
    "                \"name\": resource_type,\n",
    "                \"properties\": {}\n",
    "            })\n",
    "            \n",
    "            resource_entities.append({\n",
    "                \"id\": location,\n",
    "                \"type\": \"Location\",\n",
    "                \"name\": location,\n",
    "                \"properties\": {}\n",
    "            })\n",
    "            \n",
    "            resource_relationships.append({\n",
    "                \"source\": resource_id,\n",
    "                \"target\": resource_type,\n",
    "                \"type\": \"is_type\",\n",
    "                \"properties\": {}\n",
    "            })\n",
    "            \n",
    "            resource_relationships.append({\n",
    "                \"source\": resource_id,\n",
    "                \"target\": location,\n",
    "                \"type\": \"located_at\",\n",
    "                \"properties\": {}\n",
    "            })\n",
    "\n",
    "builder = GraphBuilder()\n",
    "graph_analyzer = GraphAnalyzer()\n",
    "centrality_calculator = CentralityCalculator()\n",
    "community_detector = CommunityDetector()\n",
    "\n",
    "resource_kg = builder.build(resource_entities, resource_relationships)\n",
    "\n",
    "metrics = graph_analyzer.compute_metrics(resource_kg)\n",
    "centrality_result = centrality_calculator.calculate_degree_centrality(resource_kg)\n",
    "centrality_scores = centrality_result.get('centrality', {})\n",
    "communities = community_detector.detect_communities(resource_kg)\n",
    "\n",
    "print(f\"Extracted {len(resource_entities)} resource entities\")\n",
    "print(f\"Extracted {len(resource_relationships)} relationships\")\n",
    "print(f\"Built resource knowledge graph with {len(resource_kg.get('entities', []))} entities\")\n",
    "print(f\"Graph density: {metrics.get('density', 0):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze Resource Efficiency\n",
    "\n",
    "Analyze resource efficiency using graph analytics and temporal patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity_analyzer = ConnectivityAnalyzer()\n",
    "temporal_query = TemporalGraphQuery()\n",
    "temporal_pattern_detector = TemporalPatternDetector()\n",
    "\n",
    "connectivity = connectivity_analyzer.analyze_connectivity(resource_kg)\n",
    "\n",
    "start_time = (datetime.now() - timedelta(hours=24)).isoformat()\n",
    "end_time = datetime.now().isoformat()\n",
    "\n",
    "temporal_results = temporal_query.query_time_range(\n",
    "    graph=resource_kg,\n",
    "    query=\"Find resource utilization in the last 24 hours\",\n",
    "    start_time=start_time,\n",
    "    end_time=end_time\n",
    ")\n",
    "\n",
    "temporal_patterns = temporal_pattern_detector.detect_temporal_patterns(\n",
    "    resource_kg,\n",
    "    pattern_type=\"efficiency\",\n",
    "    min_frequency=1\n",
    ")\n",
    "\n",
    "# Analyze efficiency metrics\n",
    "efficiency_analysis = {}\n",
    "if parsed_data and parsed_data.data:\n",
    "    for entry in parsed_data.data if isinstance(parsed_data.data, list) else [parsed_data.data]:\n",
    "        if isinstance(entry, dict):\n",
    "            resource_type = entry.get(\"resource_type\", \"\")\n",
    "            \n",
    "            if resource_type not in efficiency_analysis:\n",
    "                efficiency_analysis[resource_type] = {\n",
    "                    \"utilization\": [],\n",
    "                    \"efficiency\": [],\n",
    "                    \"capacity\": [],\n",
    "                    \"resources\": []\n",
    "                }\n",
    "            \n",
    "            efficiency_analysis[resource_type][\"utilization\"].append(entry.get(\"utilization_percent\", 0))\n",
    "            efficiency_analysis[resource_type][\"efficiency\"].append(entry.get(\"efficiency_percent\", 0))\n",
    "            efficiency_analysis[resource_type][\"capacity\"].append(entry.get(\"capacity_mw\", 0))\n",
    "            efficiency_analysis[resource_type][\"resources\"].append(entry.get(\"resource_id\", \"\"))\n",
    "\n",
    "# Calculate averages\n",
    "for resource_type, data in efficiency_analysis.items():\n",
    "    if data[\"utilization\"]:\n",
    "        efficiency_analysis[resource_type][\"avg_utilization\"] = sum(data[\"utilization\"]) / len(data[\"utilization\"])\n",
    "        efficiency_analysis[resource_type][\"avg_efficiency\"] = sum(data[\"efficiency\"]) / len(data[\"efficiency\"])\n",
    "        efficiency_analysis[resource_type][\"total_capacity\"] = sum(data[\"capacity\"])\n",
    "\n",
    "print(f\"Efficiency analysis complete\")\n",
    "print(f\"  Temporal patterns: {len(temporal_patterns)}\")\n",
    "print(f\"  Resource types analyzed: {len(efficiency_analysis)}\")\n",
    "for resource_type, data in efficiency_analysis.items():\n",
    "    print(f\"    {resource_type}: Avg Utilization {data.get('avg_utilization', 0):.1f}%, Avg Efficiency {data.get('avg_efficiency', 0):.1f}%, Total Capacity {data.get('total_capacity', 0)} MW\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Optimize Resource Allocation\n",
    "\n",
    "Optimize resource allocation using inference engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inference_engine = InferenceEngine()\n",
    "rule_manager = RuleManager()\n",
    "explanation_generator = ExplanationGenerator()\n",
    "\n",
    "# Resource optimization rules\n",
    "inference_engine.add_rule(\"IF utilization < 50 AND efficiency > 80 THEN underutilized_resource\")\n",
    "inference_engine.add_rule(\"IF utilization > 90 AND efficiency < 70 THEN overutilized_resource\")\n",
    "inference_engine.add_rule(\"IF efficiency > 90 AND utilization > 70 THEN optimal_resource\")\n",
    "\n",
    "# Optimize allocation\n",
    "optimization_suggestions = []\n",
    "if parsed_data and parsed_data.data:\n",
    "    for entry in parsed_data.data if isinstance(parsed_data.data, list) else [parsed_data.data]:\n",
    "        if isinstance(entry, dict):\n",
    "            resource_id = entry.get(\"resource_id\", \"\")\n",
    "            utilization = entry.get(\"utilization_percent\", 0)\n",
    "            efficiency = entry.get(\"efficiency_percent\", 0)\n",
    "            capacity = entry.get(\"capacity_mw\", 0)\n",
    "            \n",
    "            suggestion = {\n",
    "                \"resource_id\": resource_id,\n",
    "                \"current_utilization\": utilization,\n",
    "                \"current_efficiency\": efficiency,\n",
    "                \"recommendation\": \"\",\n",
    "                \"optimization_potential\": 0\n",
    "            }\n",
    "            \n",
    "            if utilization < 50 and efficiency > 80:\n",
    "                suggestion[\"recommendation\"] = \"Increase load allocation\"\n",
    "                suggestion[\"optimization_potential\"] = (50 - utilization) * capacity / 100\n",
    "            elif utilization > 90 and efficiency < 70:\n",
    "                suggestion[\"recommendation\"] = \"Reduce load to improve efficiency\"\n",
    "                suggestion[\"optimization_potential\"] = (utilization - 80) * capacity / 100\n",
    "            elif efficiency > 90 and utilization > 70:\n",
    "                suggestion[\"recommendation\"] = \"Optimal - maintain current allocation\"\n",
    "                suggestion[\"optimization_potential\"] = 0\n",
    "            \n",
    "            optimization_suggestions.append(suggestion)\n",
    "            \n",
    "            inference_engine.add_fact({\n",
    "                \"resource_id\": resource_id,\n",
    "                \"utilization\": utilization,\n",
    "                \"efficiency\": efficiency,\n",
    "                \"capacity\": capacity\n",
    "            })\n",
    "\n",
    "# # optimization_insights = inference_engine.forward_chain()\n",
    "\n",
    "total_optimization_potential = sum(s.get(\"optimization_potential\", 0) for s in optimization_suggestions)\n",
    "\n",
    "print(f\"Resource allocation optimization complete\")\n",
    "print(f\"  Resources analyzed: {len(optimization_suggestions)}\")\n",
    "print(f\"  Optimization suggestions: {len([s for s in optimization_suggestions if s.get('optimization_potential', 0) > 0])}\")\n",
    "print(f\"  Total optimization potential: {total_optimization_potential:.2f} MW\")\n",
    "print(f\"  Generated {len(optimization_insights)} optimization insights\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Reports and Visualize\n",
    "\n",
    "Generate resource optimization reports and visualize results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_exporter = JSONExporter()\n",
    "csv_exporter = CSVExporter()\n",
    "rdf_exporter = RDFExporter()\n",
    "report_generator = ReportGenerator()\n",
    "\n",
    "quality_score = {\"overall_score\": 0.92}\n",
    "\n",
    "json_exporter.export_knowledge_graph(resource_kg, os.path.join(temp_dir, \"resource_kg.json\"))\n",
    "csv_exporter.export_entities(resource_entities, os.path.join(temp_dir, \"resource_entities.csv\"))\n",
    "rdf_exporter.export_knowledge_graph(resource_kg, os.path.join(temp_dir, \"resource_kg.rdf\"))\n",
    "\n",
    "report_data = {\n",
    "    \"summary\": f\"Resource optimization identified {len(optimization_suggestions)} suggestions with {total_optimization_potential:.2f} MW optimization potential\",\n",
    "    \"resources_analyzed\": len(optimization_suggestions),\n",
    "    \"optimization_suggestions\": len([s for s in optimization_suggestions if s.get(\"optimization_potential\", 0) > 0]),\n",
    "    \"total_optimization_potential\": total_optimization_potential,\n",
    "    \"insights\": len(optimization_insights),\n",
    "    \"quality_score\": quality_score.get('overall_score', 0)\n",
    "}\n",
    "\n",
    "report = report_generator.generate_report(report_data, format=\"markdown\")\n",
    "\n",
    "kg_visualizer = KGVisualizer()\n",
    "analytics_visualizer = AnalyticsVisualizer()\n",
    "temporal_visualizer = TemporalVisualizer()\n",
    "\n",
    "kg_viz = kg_visualizer.visualize_network(resource_kg, output=\"interactive\")\n",
    "analytics_viz = analytics_visualizer.visualize_analytics(resource_kg, output=\"interactive\")\n",
    "temporal_viz = temporal_visualizer.visualize_timeline(resource_kg, output=\"interactive\")\n",
    "\n",
    "print(f\"Total modules used: 20+\")\n",
    "print(f\"Pipeline complete: Resource Data \u2192 Parse \u2192 Extract \u2192 Build Resource KG \u2192 Analyze Efficiency \u2192 Optimize Allocation \u2192 Reports \u2192 Visualize\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}