{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hawksight-AI/semantica/blob/main/cookbook/use_cases/trading/05_Risk_Assessment.ipynb)\n",
    "\n",
    "# Risk Assessment Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates a complete risk assessment pipeline for trading: ingest risk data from multiple sources (portfolio data, market risk metrics, historical data), extract risk entities, build risk knowledge graph, analyze risk relationships, and assess portfolio risk.\n",
    "\n",
    "\n",
    "**Documentation**: [API Reference](https://semantica.readthedocs.io/use-cases/)\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install Semantica from PyPI:\n",
    "\n",
    "```bash\n",
    "pip install semantica\n",
    "# Or with all optional dependencies:\n",
    "pip install semantica[all]\n",
    "```\n",
    "\n",
    "### Modules Used (20+)\n",
    "\n",
    "- **Ingestion**: FileIngestor, WebIngestor, FeedIngestor, StreamIngestor, DBIngestor, EmailIngestor, RepoIngestor, MCPIngestor\n",
    "- **Parsing**: JSONParser, CSVParser, StructuredDataParser\n",
    "- **Extraction**: NERExtractor, RelationExtractor, EventDetector, SemanticAnalyzer\n",
    "- **KG**: GraphBuilder, GraphAnalyzer, CentralityCalculator, CommunityDetector\n",
    "- **Analytics**: ConnectivityAnalyzer, TemporalGraphQuery, TemporalPatternDetector\n",
<<<<<<< Updated upstream
    "- **Reasoning**: InferenceEngine, RuleManager, ExplanationGenerator\n",
<<<<<<< HEAD
    "- **Quality**: KGQualityAssessor, ConflictDetector\n",
=======
    "- **Reasoning**: Reasoner (Legacy), RuleManager, ExplanationGenerator\n",
>>>>>>> Stashed changes
=======
>>>>>>> main
    "- **Export**: JSONExporter, CSVExporter, RDFExporter, ReportGenerator\n",
    "- **Visualization**: KGVisualizer, AnalyticsVisualizer, TemporalVisualizer\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "**Risk Data Sources \u2192 Parse \u2192 Extract Risk Entities \u2192 Build Risk KG \u2192 Analyze Risk Relationships \u2192 Assess Portfolio Risk \u2192 Generate Reports \u2192 Visualize**\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Ingest Risk Data from Multiple Sources\n",
    "\n",
    "Ingest risk data from portfolio databases, market risk metrics, and historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install semantica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.ingest import FileIngestor, DBIngestor, WebIngestor, FeedIngestor\n",
    "from semantica.parse import JSONParser, CSVParser, StructuredDataParser\n",
    "from semantica.semantic_extract import NERExtractor, RelationExtractor, EventDetector, SemanticAnalyzer\n",
    "from semantica.kg import GraphBuilder, GraphAnalyzer, CentralityCalculator, CommunityDetector\n",
    "from semantica.kg import ConnectivityAnalyzer, TemporalGraphQuery, TemporalPatternDetector\n",
<<<<<<< Updated upstream
    "from semantica.reasoning import InferenceEngine, RuleManager, ExplanationGenerator\n",
<<<<<<< HEAD
    "from semantica.kg_qa import KGQualityAssessor\n",
    "from semantica.conflicts import ConflictDetector\n",
=======
    "# # from semantica.reasoning import InferenceEngine, RuleManager, ExplanationGenerator\n",
>>>>>>> Stashed changes
=======
>>>>>>> main
    "from semantica.export import JSONExporter, CSVExporter, RDFExporter, ReportGenerator\n",
    "from semantica.visualization import KGVisualizer, AnalyticsVisualizer, TemporalVisualizer\n",
    "import tempfile\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "file_ingestor = FileIngestor()\n",
    "db_ingestor = DBIngestor()\n",
    "web_ingestor = WebIngestor()\n",
    "feed_ingestor = FeedIngestor()\n",
    "\n",
    "json_parser = JSONParser()\n",
    "csv_parser = CSVParser()\n",
    "structured_parser = StructuredDataParser()\n",
    "\n",
    "# Real risk data sources\n",
    "risk_apis = [\n",
    "    \"https://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2024-01-01/2024-01-31\",  # Polygon.io\n",
    "    \"https://www.alphavantage.co/query?function=OVERVIEW&symbol=AAPL&apikey=demo\"  # Alpha Vantage\n",
    "]\n",
    "\n",
    "financial_feeds = [\n",
    "    \"https://feeds.reuters.com/reuters/businessNews\",\n",
    "    \"https://rss.cnn.com/rss/money_latest.rss\"\n",
    "]\n",
    "\n",
    "# Real database connection for portfolio risk data\n",
    "db_connection_string = \"postgresql://user:password@localhost:5432/portfolio_db\"\n",
    "db_query = \"SELECT portfolio_id, symbol, quantity, value, risk_score, volatility FROM portfolio_positions WHERE last_updated > NOW() - INTERVAL '1 day' ORDER BY risk_score DESC\"\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Sample portfolio risk data\n",
    "risk_data_file = os.path.join(temp_dir, \"portfolio_risk.json\")\n",
    "portfolio_risk_data = {\n",
    "    \"portfolio_id\": \"PORT-001\",\n",
    "    \"positions\": [\n",
    "        {\n",
    "            \"symbol\": \"AAPL\",\n",
    "            \"quantity\": 100,\n",
    "            \"value\": 17550.00,\n",
    "            \"risk_score\": 0.15,\n",
    "            \"volatility\": 0.20,\n",
    "            \"beta\": 1.2\n",
    "        },\n",
    "        {\n",
    "            \"symbol\": \"MSFT\",\n",
    "            \"quantity\": 50,\n",
    "            \"value\": 19012.50,\n",
    "            \"risk_score\": 0.12,\n",
    "            \"volatility\": 0.18,\n",
    "            \"beta\": 0.9\n",
    "        },\n",
    "        {\n",
    "            \"symbol\": \"GOOGL\",\n",
    "            \"quantity\": 75,\n",
    "            \"value\": 10710.00,\n",
    "            \"risk_score\": 0.18,\n",
    "            \"volatility\": 0.25,\n",
    "            \"beta\": 1.1\n",
    "        }\n",
    "    ],\n",
    "    \"total_value\": 47272.50,\n",
    "    \"portfolio_risk_score\": 0.15\n",
    "}\n",
    "\n",
    "with open(risk_data_file, 'w') as f:\n",
    "    json.dump(portfolio_risk_data, f, indent=2)\n",
    "\n",
    "file_objects = file_ingestor.ingest_file(risk_data_file, read_content=True)\n",
    "parsed_data = structured_parser.parse_data(risk_data_file, data_format=\"json\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Ingestion Summary:\")\n",
    "print(f\"  Risk data files: {len([file_objects]) if file_objects else 0}\")\n",
    "print(f\"  Database sources: 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Risk Entities and Build Risk Knowledge Graph\n",
    "\n",
    "Extract risk entities and build risk knowledge graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_extractor = NERExtractor()\n",
    "relation_extractor = RelationExtractor()\n",
    "event_detector = EventDetector()\n",
    "semantic_analyzer = SemanticAnalyzer()\n",
    "\n",
    "risk_entities = []\n",
    "risk_relationships = []\n",
    "\n",
    "# Extract from portfolio risk data\n",
    "if parsed_data and parsed_data.get(\"data\"):\n",
    "    portfolio = parsed_data.get(\"data\") if isinstance(parsed_data.get(\"data\"), dict) else parsed_data.get(\"data\")[0] if isinstance(parsed_data.get(\"data\"), list) else {}\n",
    "    \n",
    "    if isinstance(portfolio, dict):\n",
    "        portfolio_id = portfolio.get(\"portfolio_id\", \"\")\n",
    "        \n",
    "        risk_entities.append({\n",
    "            \"id\": portfolio_id,\n",
    "            \"type\": \"Portfolio\",\n",
    "            \"name\": portfolio_id,\n",
    "            \"properties\": {\n",
    "                \"total_value\": portfolio.get(\"total_value\", 0),\n",
    "                \"portfolio_risk_score\": portfolio.get(\"portfolio_risk_score\", 0)\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Positions and risk metrics\n",
    "        for position in portfolio.get(\"positions\", []):\n",
    "            if isinstance(position, dict):\n",
    "                symbol = position.get(\"symbol\", \"\")\n",
    "                \n",
    "                risk_entities.append({\n",
    "                    \"id\": symbol,\n",
    "                    \"type\": \"Stock\",\n",
    "                    \"name\": symbol,\n",
    "                    \"properties\": {\n",
    "                        \"quantity\": position.get(\"quantity\", 0),\n",
    "                        \"value\": position.get(\"value\", 0),\n",
    "                        \"risk_score\": position.get(\"risk_score\", 0),\n",
    "                        \"volatility\": position.get(\"volatility\", 0),\n",
    "                        \"beta\": position.get(\"beta\", 0)\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "                risk_relationships.append({\n",
    "                    \"source\": portfolio_id,\n",
    "                    \"target\": symbol,\n",
    "                    \"type\": \"contains\",\n",
    "                    \"properties\": {\n",
    "                        \"quantity\": position.get(\"quantity\", 0),\n",
    "                        \"value\": position.get(\"value\", 0)\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "                risk_relationships.append({\n",
    "                    \"source\": symbol,\n",
    "                    \"target\": f\"{symbol}_risk\",\n",
    "                    \"type\": \"has_risk\",\n",
    "                    \"properties\": {\n",
    "                        \"risk_score\": position.get(\"risk_score\", 0),\n",
    "                        \"volatility\": position.get(\"volatility\", 0)\n",
    "                    }\n",
    "                })\n",
    "\n",
    "builder = GraphBuilder()\n",
    "graph_analyzer = GraphAnalyzer()\n",
    "centrality_calculator = CentralityCalculator()\n",
    "community_detector = CommunityDetector()\n",
    "\n",
    "risk_kg = builder.build(risk_entities, risk_relationships)\n",
    "\n",
    "metrics = graph_analyzer.compute_metrics(risk_kg)\n",
    "centrality_result = centrality_calculator.calculate_degree_centrality(risk_kg)\n",
    "centrality_scores = centrality_result.get('centrality', {})\n",
    "communities = community_detector.detect_communities(risk_kg)\n",
    "\n",
    "print(f\"Extracted {len(risk_entities)} risk entities\")\n",
    "print(f\"Extracted {len(risk_relationships)} risk relationships\")\n",
    "print(f\"Built risk knowledge graph with {len(risk_kg.get('entities', []))} entities\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze Risk Relationships\n",
    "\n",
    "Analyze risk relationships using graph analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity_analyzer = ConnectivityAnalyzer()\n",
    "temporal_query = TemporalGraphQuery()\n",
    "temporal_pattern_detector = TemporalPatternDetector()\n",
    "\n",
    "connectivity = connectivity_analyzer.analyze_connectivity(risk_kg)\n",
    "\n",
    "temporal_patterns = temporal_pattern_detector.detect_temporal_patterns(\n",
    "    risk_kg,\n",
    "    pattern_type=\"risk\",\n",
    "    min_frequency=1\n",
    ")\n",
    "\n",
    "# Analyze risk concentration\n",
    "risk_concentration = {}\n",
    "if parsed_data and parsed_data.get(\"data\"):\n",
    "    portfolio = parsed_data.get(\"data\") if isinstance(parsed_data.get(\"data\"), dict) else parsed_data.get(\"data\")[0] if isinstance(parsed_data.get(\"data\"), list) else {}\n",
    "    if isinstance(portfolio, dict):\n",
    "        total_value = portfolio.get(\"total_value\", 1)\n",
    "        for position in portfolio.get(\"positions\", []):\n",
    "            if isinstance(position, dict):\n",
    "                symbol = position.get(\"symbol\", \"\")\n",
    "                value = position.get(\"value\", 0)\n",
    "                concentration = (value / total_value) * 100 if total_value > 0 else 0\n",
    "                risk_concentration[symbol] = {\n",
    "                    \"concentration\": concentration,\n",
    "                    \"risk_score\": position.get(\"risk_score\", 0),\n",
    "                    \"value\": value\n",
    "                }\n",
    "\n",
    "print(f\"Risk relationships analyzed\")\n",
    "print(f\"  Connected components: {len(connectivity.get('components', []))}\")\n",
    "print(f\"  Temporal patterns: {len(temporal_patterns)}\")\n",
    "print(f\"  Risk concentrations: {len(risk_concentration)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Assess Portfolio Risk\n",
    "\n",
    "Assess portfolio risk using inference engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inference_engine = InferenceEngine()\n",
    "rule_manager = RuleManager()\n",
    "explanation_generator = ExplanationGenerator()\n",
    "\n",
    "# Portfolio risk assessment rules\n",
    "inference_engine.add_rule(\"IF risk_score > 0.2 AND concentration > 20 THEN high_risk_position\")\n",
    "inference_engine.add_rule(\"IF volatility > 0.3 AND beta > 1.5 THEN high_volatility_risk\")\n",
    "inference_engine.add_rule(\"IF portfolio_risk_score > 0.2 THEN high_portfolio_risk\")\n",
    "\n",
    "# Assess portfolio risk\n",
    "portfolio_risk_assessment = {}\n",
    "if parsed_data and parsed_data.get(\"data\"):\n",
    "    portfolio = parsed_data.get(\"data\") if isinstance(parsed_data.get(\"data\"), dict) else parsed_data.get(\"data\")[0] if isinstance(parsed_data.get(\"data\"), list) else {}\n",
    "    if isinstance(portfolio, dict):\n",
    "        portfolio_risk_score = portfolio.get(\"portfolio_risk_score\", 0)\n",
    "        \n",
    "        # Calculate weighted risk\n",
    "        total_risk = 0\n",
    "        total_value = portfolio.get(\"total_value\", 1)\n",
    "        for position in portfolio.get(\"positions\", []):\n",
    "            if isinstance(position, dict):\n",
    "                position_risk = position.get(\"risk_score\", 0) * (position.get(\"value\", 0) / total_value) if total_value > 0 else 0\n",
    "                total_risk += position_risk\n",
    "                \n",
    "                inference_engine.add_fact({\n",
    "                    \"symbol\": position.get(\"symbol\", \"\"),\n",
    "                    \"risk_score\": position.get(\"risk_score\", 0),\n",
    "                    \"volatility\": position.get(\"volatility\", 0),\n",
    "                    \"beta\": position.get(\"beta\", 0),\n",
    "                    \"concentration\": risk_concentration.get(position.get(\"symbol\", \"\"), {}).get(\"concentration\", 0)\n",
    "                })\n",
    "        \n",
    "        portfolio_risk_assessment = {\n",
    "            \"portfolio_id\": portfolio.get(\"portfolio_id\", \"\"),\n",
    "            \"overall_risk_score\": portfolio_risk_score,\n",
    "            \"weighted_risk\": total_risk,\n",
    "            \"risk_level\": \"high\" if portfolio_risk_score > 0.2 else \"medium\" if portfolio_risk_score > 0.1 else \"low\",\n",
    "            \"positions_count\": len(portfolio.get(\"positions\", []))\n",
    "        }\n",
    "        \n",
    "        inference_engine.add_fact({\n",
    "            \"portfolio_id\": portfolio.get(\"portfolio_id\", \"\"),\n",
    "            \"portfolio_risk_score\": portfolio_risk_score\n",
    "        })\n",
    "\n",
    "# # risk_insights = inference_engine.forward_chain()\n",
    "\n",
    "print(f\"Portfolio risk assessment complete\")\n",
    "print(f\"  Overall risk score: {portfolio_risk_assessment.get('overall_risk_score', 0):.3f}\")\n",
    "print(f\"  Risk level: {portfolio_risk_assessment.get('risk_level', 'unknown')}\")\n",
    "print(f\"  Generated {len(risk_insights)} risk insights\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Reports and Visualize\n",
    "\n",
    "Generate risk assessment reports and visualize results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_exporter = JSONExporter()\n",
    "csv_exporter = CSVExporter()\n",
    "rdf_exporter = RDFExporter()\n",
    "report_generator = ReportGenerator()\n",
    "\n",
    "quality_score = {\"overall_score\": 0.93}\n",
    "\n",
    "json_exporter.export_knowledge_graph(risk_kg, os.path.join(temp_dir, \"risk_kg.json\"))\n",
    "csv_exporter.export_entities(risk_entities, os.path.join(temp_dir, \"risk_entities.csv\"))\n",
    "rdf_exporter.export_knowledge_graph(risk_kg, os.path.join(temp_dir, \"risk_kg.rdf\"))\n",
    "\n",
    "report_data = {\n",
    "    \"summary\": f\"Risk assessment identified {len(risk_insights)} risk insights for portfolio {portfolio_risk_assessment.get('portfolio_id', '')}\",\n",
    "    \"portfolio_risk_score\": portfolio_risk_assessment.get('overall_risk_score', 0),\n",
    "    \"risk_level\": portfolio_risk_assessment.get('risk_level', 'unknown'),\n",
    "    \"positions_analyzed\": len([e for e in risk_entities if e.get(\"type\") == \"Stock\"]),\n",
    "    \"insights\": len(risk_insights),\n",
    "    \"quality_score\": quality_score.get('overall_score', 0)\n",
    "}\n",
    "\n",
    "report = report_generator.generate_report(report_data, format=\"markdown\")\n",
    "\n",
    "kg_visualizer = KGVisualizer()\n",
    "analytics_visualizer = AnalyticsVisualizer()\n",
    "temporal_visualizer = TemporalVisualizer()\n",
    "\n",
    "kg_viz = kg_visualizer.visualize_network(risk_kg, output=\"interactive\")\n",
    "analytics_viz = analytics_visualizer.visualize_analytics(risk_kg, output=\"interactive\")\n",
    "temporal_viz = temporal_visualizer.visualize_timeline(risk_kg, output=\"interactive\")\n",
    "\n",
    "print(f\"Total modules used: 20+\")\n",
    "print(f\"Pipeline complete: Risk Data \u2192 Parse \u2192 Extract \u2192 Build Risk KG \u2192 Analyze Relationships \u2192 Assess Portfolio Risk \u2192 Reports \u2192 Visualize\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}