{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d1a12c",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< Updated upstream
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hawksight-AI/semantica/blob/main/cookbook/use_cases/advanced_rag/01_GraphRAG_Complete.ipynb)\n",
    "\n",
    "# GraphRAG Complete - End-to-End Pipeline\n",
=======
    "# \ud83e\uddea GraphRAG: Skincare Intelligence System\n",
    "## \ud83d\udcd6 Overview\n",
    "This notebook demonstrates the construction and querying of a **highly detailed Knowledge Graph** for the Skincare and Dermatology domain using the Semantica framework.\n",
    "\n",
    "### \ud83c\udfd7\ufe0f Pipeline Architecture\n",
=======
    "# ðŸ§ª GraphRAG: Skincare Intelligence System\n",
    "## ðŸ“– Overview\n",
    "This notebook demonstrates the construction and querying of a **highly detailed Knowledge Graph** for the Skincare and Dermatology domain using the Semantica framework.\n",
    "\n",
    "### ðŸ—ï¸ Pipeline Architecture\n",
>>>>>>> main
    "1. **Phase 0: Foundation**: Environment setup and \"Ground Truth\" seeding.\n",
    "2. **Phase 1: Multi-Source Ingestion**: Aggregating knowledge from Expert RSS Feeds and clinical guides.\n",
    "3. **Phase 2: Semantic Extraction**: Deep extraction of entities and relationships using Llama 3.1.\n",
    "4. **Phase 3: Refinement**: Autonomous deduplication and conflict resolution.\n",
    "5. **Phase 4: Multi-Hop Question Answering**: Interactive user queries using **AgentContext (Hybrid Retrieval)**."
<<<<<<< HEAD
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdef52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~gno (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~gno (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~gno (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install -qU semantica networkx matplotlib plotly pandas faiss-cpu beautifulsoup4 groq sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508c1ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fastembed not available. Install with: pip install fastembed. Using fallback embedding method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Phase 0 Complete. Seeded 3 primary nodes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from semantica.core import Semantica, ConfigManager\n",
    "from semantica.seed import SeedDataManager\n",
    "from semantica.vector_store import VectorStore\n",
>>>>>>> Stashed changes
    "\n",
    "## Overview\n",
    "\n",
<<<<<<< Updated upstream
    "This notebook demonstrates a **complete end-to-end GraphRAG (Graph-based Retrieval Augmented Generation) system** using Semantica framework. It showcases how to build a production-ready GraphRAG system that combines vector search with knowledge graph traversal for enhanced retrieval and question answering.\n",
=======
    "config_dict = {\n",
    "    \"project_name\": \"Skincare_Intelligence\",\n",
    "    \"embedding\": {\"provider\": \"sentence_transformers\", \"model\": \"all-MiniLM-L6-v2\"}, \n",
    "    \"extraction\": {\n",
    "        \"provider\": \"groq\", \n",
    "        \"model\": \"llama-3.1-8b-instant\", \n",
    "        \"temperature\": 0.0\n",
    "    },\n",
    "# #     \"inference\": {\n",
    "        \"provider\": \"groq\",\n",
    "        \"model\": \"llama-3.1-70b-versatile\"\n",
    "    },\n",
    "    \"vector_store\": {\"provider\": \"faiss\", \"dimension\": 384},\n",
    "    \"knowledge_graph\": {\"backend\": \"networkx\", \"merge_entities\": True}\n",
    "}\n",
>>>>>>> Stashed changes
    "\n",
    "**Key Features:**\n",
    "\n",
    "- **Real-World Data**: Uses actual data sources via MCP servers, web scraping, and RSS feeds (NO mock data)\n",
    "- **Complete Pipeline**: From data ingestion to LLM-powered question answering\n",
    "- **Hybrid Retrieval**: Combines vector similarity search with knowledge graph traversal\n",
    "- **Multi-hop Reasoning**: Follows relationships across the graph for deeper context\n",
    "- **20+ Semantica Modules**: Demonstrates comprehensive use of the framework\n",
    "\n",
    "**Documentation**: [API Reference](https://semantica.readthedocs.io/concepts/) â€¢ [GraphRAG Guide](https://semantica.readthedocs.io/concepts/)\n",
    "\n",
<<<<<<< Updated upstream
    "### What You'll Learn\n",
    "\n",
    "- How to ingest real-world data from multiple sources (MCP, web, feeds)\n",
    "- How to build knowledge graphs from unstructured text\n",
    "- How to implement hybrid search combining vectors and graphs\n",
    "- How to use ContextRetriever for intelligent context expansion\n",
    "- How to integrate LLMs with GraphRAG for question answering\n",
    "- How to visualize and export knowledge graphs\n",
    "\n",
    "### Pipeline Overview\n",
    "\n",
    "**Real-World Data Sources (MCP/Web/Feeds) â†’ Parse â†’ Extract Entities & Relationships â†’ Build Knowledge Graph â†’ Generate Embeddings â†’ Vector Store â†’ Hybrid Search â†’ Context Retrieval â†’ GraphRAG Query System â†’ LLM Integration â†’ Answer Generation**\n",
    "\n",
    "---\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install Semantica from PyPI:\n",
    "\n",
    "```bash\n",
    "pip install semantica\n",
    "\n",
    "# Or with all optional dependencies:\n",
    "pip install semantica[all]\n",
    "```\n",
    "\n",
    "### Additional Dependencies\n",
    "\n",
    "```bash\n",
    "pip install openai anthropic  # For LLM integration\n",
    "pip install jupyter           # For running this notebook\n",
    "```\n"
=======
    "print(f\"\u2705 Phase 0 Complete. Seeded {len(foundation_data['entities'])} primary nodes.\")"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< Updated upstream
    "## Step 1: Setup and Import Semantica Modules\n",
    "\n",
    "Import all necessary Semantica modules for the complete GraphRAG pipeline. This includes modules for ingestion, parsing, extraction, graph building, embeddings, vector storage, context retrieval, and more.\n",
    "\n"
=======
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdef52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~gno (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~gno (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~gno (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install -qU semantica networkx matplotlib plotly pandas faiss-cpu beautifulsoup4 groq sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508c1ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fastembed not available. Install with: pip install fastembed. Using fallback embedding method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Phase 0 Complete. Seeded 3 primary nodes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from semantica.core import Semantica, ConfigManager\n",
    "from semantica.seed import SeedDataManager\n",
    "from semantica.vector_store import VectorStore\n",
    "\n",
    "# 1. Groq Configuration\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "config_dict = {\n",
    "    \"project_name\": \"Skincare_Intelligence\",\n",
    "    \"embedding\": {\"provider\": \"sentence_transformers\", \"model\": \"all-MiniLM-L6-v2\"}, \n",
    "    \"extraction\": {\n",
    "        \"provider\": \"groq\", \n",
    "        \"model\": \"llama-3.1-8b-instant\", \n",
    "        \"temperature\": 0.0\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"provider\": \"groq\",\n",
    "        \"model\": \"llama-3.1-70b-versatile\"\n",
    "    },\n",
    "    \"vector_store\": {\"provider\": \"faiss\", \"dimension\": 384},\n",
    "    \"knowledge_graph\": {\"backend\": \"networkx\", \"merge_entities\": True}\n",
    "}\n",
    "\n",
    "config = ConfigManager().load_from_dict(config_dict)\n",
    "core = Semantica(config=config)\n",
    "vs = VectorStore(backend=\"faiss\", dimension=384)\n",
    "\n",
    "# 2. Seeding Ground Truth\n",
    "foundation_data = {\n",
    "    \"entities\": [\n",
    "        {\"id\": \"hyaluronic_acid\", \"name\": \"Hyaluronic Acid\", \"type\": \"Ingredient\", \"properties\": {\"role\": \"Humectant\"}},\n",
    "        {\"id\": \"retinol\", \"name\": \"Retinol\", \"type\": \"Ingredient\", \"properties\": {\"role\": \"Anti-aging actives\"}},\n",
    "        {\"id\": \"niacinamide\", \"name\": \"Niacinamide\", \"type\": \"Ingredient\", \"properties\": {\"role\": \"Barrier repair\"}}\n",
    "    ],\n",
    "    \"relationships\": [\n",
    "        {\"source\": \"hyaluronic_acid\", \"target\": \"niacinamide\", \"type\": \"COMPLEMENTS\", \"properties\": {\"benefit\": \"Hydration + Barrier\"}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"skincare_base.json\", \"w\") as f: json.dump(foundation_data, f)\n",
    "seed_manager = SeedDataManager()\n",
    "seed_manager.register_source(\"core_ontology\", \"json\", \"skincare_base.json\")\n",
    "foundation_graph = seed_manager.create_foundation_graph()\n",
    "\n",
    "print(f\"âœ… Phase 0 Complete. Seeded {len(foundation_data['entities'])} primary nodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a2ebc",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Phase 1: Ingestion & Processing\n",
    "We pull real-world knowledge from expert feeds and clinical guides, then split them into semantic chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f20118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting from: https://makeupandbeautyblog.com/feed\n",
      "Ingesting from: https://www.drbaileyskincare.com/blogs/blog.atom\n",
      "âœ… Phase 1 Complete. Generated 74 semantic chunks.\n"
     ]
    }
   ],
   "source": [
    "from semantica.ingest import FeedIngestor\n",
    "from semantica.split import EntityAwareChunker\n",
    "from semantica.normalize import TextNormalizer\n",
    "\n",
    "sources = []\n",
    "feed_ingestor = FeedIngestor()\n",
    "\n",
    "# 1. RSS Ingestion\n",
    "feed_urls = [\n",
    "    \"https://makeupandbeautyblog.com/feed\",\n",
    "    \"https://www.drbaileyskincare.com/blogs/blog.atom\"\n",
    "]\n",
    "\n",
    "for url in feed_urls:\n",
    "    try:\n",
    "        print(f\"Ingesting from: {url}\")\n",
    "        feed_data = feed_ingestor.ingest_feed(url)\n",
    "        sources.extend([item.content or item.description for item in feed_data.items[:3]])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to ingest {url}: {e}\")\n",
    "\n",
    "# 2. Local Expert Guide\n",
    "expert_content = \"\"\"\n",
    "RETINOL CLINICAL GUIDE\n",
    "Mechanism: Binds to retinoic acid receptors to increase cellular turnover.\n",
    "Precautions: Should not be used with high-concentration AHA/BHA exfoliants.\n",
    "Synergy: Highly effective when paired with Niacinamide to offset potential erythema.\n",
    "\"\"\"\n",
    "sources.append(expert_content)\n",
    "\n",
    "# 3. Chunking & Normalization\n",
    "normalizer = TextNormalizer()\n",
    "chunker = EntityAwareChunker(chunk_size=1000, chunk_overlap=200)\n",
    "all_chunks = []\n",
    "for text in sources:\n",
    "    if not text: continue\n",
    "    norm_text = normalizer.normalize(text)\n",
    "    all_chunks.extend(chunker.chunk(norm_text))\n",
    "\n",
    "print(f\"âœ… Phase 1 Complete. Generated {len(all_chunks)} semantic chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c9cc0",
   "metadata": {},
   "source": [
    "## ðŸ§  Phase 2: Semantic Extraction\n",
    "Using **Groq (Llama 3.1 8B)** to extract entities and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10be6143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting intelligence from chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM relation extraction failed: Failed to parse JSON from Groq response: No JSON structure found in response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Phase 2 Complete. Extracted 29 entities.\n"
     ]
    }
   ],
   "source": [
    "from semantica.semantic_extract import NERExtractor, RelationExtractor\n",
    "\n",
    "ner = NERExtractor(method=\"llm\", provider=\"groq\", model=\"llama-3.1-8b-instant\")\n",
    "rel_ext = RelationExtractor(method=\"llm\", provider=\"groq\", model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "combined_results = {\"entities\": [], \"relationships\": []}\n",
    "\n",
    "print(\"Extracting intelligence from chunks...\")\n",
    "for chunk in all_chunks[:5]:\n",
    "    txt = str(chunk.text)\n",
    "    entities = ner.extract(txt)\n",
    "    combined_results[\"entities\"].extend([{\"name\": e.text, \"type\": e.label, \"id\": e.text.lower().replace(' ', '_')} for e in entities])\n",
    "    relations = rel_ext.extract(txt, entities=entities)\n",
    "    combined_results[\"relationships\"].extend([{\"source\": r.subject, \"target\": r.object, \"type\": r.predicate} for r in relations])\n",
    "\n",
    "print(f\"âœ… Phase 2 Complete. Extracted {len(combined_results['entities'])} entities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef80273",
   "metadata": {},
   "source": [
    "## âœ¨ Phase 3: Graph Refinement\n",
    "Merging fragments and building the final Knowledge Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c836e86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fastembed not available. Install with: pip install fastembed. Using fallback embedding method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Phase 3 Complete. Graph contains 10 resolved entities.\n"
     ]
    }
   ],
   "source": [
    "from semantica.kg import GraphBuilder, EntityResolver\n",
    "\n",
    "# 1. Build & Vectorize\n",
    "gb = GraphBuilder(merge_entities=True)\n",
    "kg = gb.build(sources=[combined_results])\n",
    "\n",
    "# 2. Deduplicate\n",
    "resolver = EntityResolver(similarity_threshold=0.85)\n",
    "kg_final = {**kg, 'entities': resolver.resolve_entities(kg['entities'])}\n",
    "\n",
    "# 3. Populate Vector Store for retrieval\n",
    "texts = [str(c.text) for c in all_chunks]\n",
    "embeddings = core.embedding_generator.generate_embeddings(texts)\n",
    "vs.store_vectors(vectors=embeddings, metadata=[{\"text\": t} for t in texts])\n",
    "\n",
    "print(f\"âœ… Phase 3 Complete. Graph contains {len(kg_final['entities'])} resolved entities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbe42a",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Phase 4: Interactive GraphRAG Question Answering\n",
    "Using **AgentContext** for unified hybrid retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d04181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Processing Multi-Hop Query: What ingredients synergize with Retinol to prevent irritation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\linalg.py:2582: RuntimeWarning:\n",
      "\n",
      "overflow encountered in multiply\n",
      "\n",
      "C:\\Users\\Mohd Kaif\\semantica\\semantica\\vector_store\\vector_store.py:498: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âŒ No relevant context found.\n"
     ]
    }
   ],
   "source": [
    "from semantica.context import AgentContext\n",
    "from semantica.reasoning import InferenceEngine\n",
    "\n",
    "# 1. Initialize AgentContext (Hybrid Retrieval)\n",
    "ctx = AgentContext(\n",
    "    vector_store=vs,\n",
    "    knowledge_graph=kg_final,\n",
    "    use_graph_expansion=True,\n",
    "    max_expansion_hops=2\n",
    ")\n",
    "\n",
    "engine = InferenceEngine(provider=\"groq\", model=\"llama-3.1-70b-versatile\")\n",
    "\n",
    "# 2. Interactive Query Loop\n",
    "user_query = \"What ingredients synergize with Retinol to prevent irritation?\"\n",
    "\n",
    "print(f\"\\nðŸ” Processing Multi-Hop Query: {user_query}\")\n",
    "\n",
    "# Retrieve multi-hop context using AgentContext\n",
    "context_results = ctx.retrieve(user_query, max_results=2)\n",
    "\n",
    "if context_results:\n",
    "    print(\"\\n--- ðŸ§  MULTI-HOP CONTEXT DISCOVERED ---\")\n",
    "    for res in context_results:\n",
    "        print(f\"Recall: {res['content'][:120]}...\")\n",
    "        if res.get('related_entities'):\n",
    "            print(f\"  ðŸ”— Multi-hop connections: {[e['content'] for e in res['related_entities'][:3]]}\")\n",
    "\n",
    "    # Generate Final Answer\n",
    "    context_text = \" \".join([r['content'] for r in context_results])\n",
    "    prompt = f\"Based on the following context, answer the user query accurately.\\nContext: {context_text}\\nQuery: {user_query}\"\n",
    "    \n",
    "    try:\n",
    "        final_answer = engine.generate(prompt)\n",
    "        print(\"\\n--- âœ¨ FINAL GRAPHRAG ANSWER ---\")\n",
    "        print(final_answer)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n(LLM synthesis skipped: {e})\")\n",
    "else:\n",
    "    print(\"\\nâŒ No relevant context found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c478f11",
   "metadata": {},
   "source": [
    "## ðŸ“Š Visualizing the Intelligence\n",
    "A final look at the relationships we've built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "851383de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.visualization import KGVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "viz = KGVisualizer()\n",
    "viz.visualize_network(kg_final, layout=\"spring\", title=\"Skincare Ingredient Intelligence Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45000b6",
   "metadata": {},
   "outputs": [],
   "source": []
=======
    "## \ud83d\udce5 Phase 1: Ingestion & Processing\n",
    "We pull real-world knowledge from expert feeds and clinical guides, then split them into semantic chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f20118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting from: https://makeupandbeautyblog.com/feed\n",
      "Ingesting from: https://www.drbaileyskincare.com/blogs/blog.atom\n",
      "\u2705 Phase 1 Complete. Generated 74 semantic chunks.\n"
     ]
    }
   ],
   "source": [
    "from semantica.ingest import FeedIngestor\n",
    "from semantica.split import EntityAwareChunker\n",
    "from semantica.normalize import TextNormalizer\n",
    "\n",
    "sources = []\n",
    "feed_ingestor = FeedIngestor()\n",
    "\n",
    "# 1. RSS Ingestion\n",
    "feed_urls = [\n",
    "    \"https://makeupandbeautyblog.com/feed\",\n",
    "    \"https://www.drbaileyskincare.com/blogs/blog.atom\"\n",
    "]\n",
    "\n",
    "for url in feed_urls:\n",
    "    try:\n",
    "        print(f\"Ingesting from: {url}\")\n",
    "        feed_data = feed_ingestor.ingest_feed(url)\n",
    "        sources.extend([item.content or item.description for item in feed_data.items[:3]])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to ingest {url}: {e}\")\n",
    "\n",
    "# 2. Local Expert Guide\n",
    "expert_content = \"\"\"\n",
    "RETINOL CLINICAL GUIDE\n",
    "Mechanism: Binds to retinoic acid receptors to increase cellular turnover.\n",
    "Precautions: Should not be used with high-concentration AHA/BHA exfoliants.\n",
    "Synergy: Highly effective when paired with Niacinamide to offset potential erythema.\n",
    "\"\"\"\n",
    "sources.append(expert_content)\n",
    "\n",
    "# 3. Chunking & Normalization\n",
    "normalizer = TextNormalizer()\n",
    "chunker = EntityAwareChunker(chunk_size=1000, chunk_overlap=200)\n",
    "all_chunks = []\n",
    "for text in sources:\n",
    "    if not text: continue\n",
    "    norm_text = normalizer.normalize(text)\n",
    "    all_chunks.extend(chunker.chunk(norm_text))\n",
    "\n",
    "print(f\"\u2705 Phase 1 Complete. Generated {len(all_chunks)} semantic chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c9cc0",
   "metadata": {},
   "source": [
    "## \ud83e\udde0 Phase 2: Semantic Extraction\n",
    "Using **Groq (Llama 3.1 8B)** to extract entities and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10be6143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting intelligence from chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM relation extraction failed: Failed to parse JSON from Groq response: No JSON structure found in response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Phase 2 Complete. Extracted 29 entities.\n"
     ]
    }
   ],
   "source": [
    "from semantica.semantic_extract import NERExtractor, RelationExtractor\n",
    "\n",
    "ner = NERExtractor(method=\"llm\", provider=\"groq\", model=\"llama-3.1-8b-instant\")\n",
    "rel_ext = RelationExtractor(method=\"llm\", provider=\"groq\", model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "combined_results = {\"entities\": [], \"relationships\": []}\n",
    "\n",
    "print(\"Extracting intelligence from chunks...\")\n",
    "for chunk in all_chunks[:5]:\n",
    "    txt = str(chunk.text)\n",
    "    entities = ner.extract(txt)\n",
    "    combined_results[\"entities\"].extend([{\"name\": e.text, \"type\": e.label, \"id\": e.text.lower().replace(' ', '_')} for e in entities])\n",
    "    relations = rel_ext.extract(txt, entities=entities)\n",
    "    combined_results[\"relationships\"].extend([{\"source\": r.subject, \"target\": r.object, \"type\": r.predicate} for r in relations])\n",
    "\n",
    "print(f\"\u2705 Phase 2 Complete. Extracted {len(combined_results['entities'])} entities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef80273",
   "metadata": {},
   "source": [
    "## \u2728 Phase 3: Graph Refinement\n",
    "Merging fragments and building the final Knowledge Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c836e86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fastembed not available. Install with: pip install fastembed. Using fallback embedding method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Phase 3 Complete. Graph contains 10 resolved entities.\n"
     ]
    }
   ],
   "source": [
    "from semantica.kg import GraphBuilder, EntityResolver\n",
    "\n",
    "# 1. Build & Vectorize\n",
    "gb = GraphBuilder(merge_entities=True)\n",
    "kg = gb.build(sources=[combined_results])\n",
    "\n",
    "# 2. Deduplicate\n",
    "resolver = EntityResolver(similarity_threshold=0.85)\n",
    "kg_final = {**kg, 'entities': resolver.resolve_entities(kg['entities'])}\n",
    "\n",
    "# 3. Populate Vector Store for retrieval\n",
    "texts = [str(c.text) for c in all_chunks]\n",
    "embeddings = core.embedding_generator.generate_embeddings(texts)\n",
    "vs.store_vectors(vectors=embeddings, metadata=[{\"text\": t} for t in texts])\n",
    "\n",
    "print(f\"\u2705 Phase 3 Complete. Graph contains {len(kg_final['entities'])} resolved entities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbe42a",
   "metadata": {},
   "source": [
    "## \ud83d\udcac Phase 4: Interactive GraphRAG Question Answering\n",
    "Using **AgentContext** for unified hybrid retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d04181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ud83d\udd0d Processing Multi-Hop Query: What ingredients synergize with Retinol to prevent irritation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\linalg.py:2582: RuntimeWarning:\n",
      "\n",
      "overflow encountered in multiply\n",
      "\n",
      "C:\\Users\\Mohd Kaif\\semantica\\semantica\\vector_store\\vector_store.py:498: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u274c No relevant context found.\n"
     ]
    }
   ],
   "source": [
    "from semantica.context import AgentContext\n",
    "\n",
    "# 1. Initialize AgentContext (Hybrid Retrieval)\n",
    "ctx = AgentContext(\n",
    "    vector_store=vs,\n",
    "    knowledge_graph=kg_final,\n",
    "    use_graph_expansion=True,\n",
    "    max_expansion_hops=2\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Interactive Query Loop\n",
    "user_query = \"What ingredients synergize with Retinol to prevent irritation?\"\n",
    "\n",
    "print(f\"\\n\ud83d\udd0d Processing Multi-Hop Query: {user_query}\")\n",
    "\n",
    "# Retrieve multi-hop context using AgentContext\n",
    "context_results = ctx.retrieve(user_query, max_results=2)\n",
    "\n",
    "if context_results:\n",
    "    print(\"\\n--- \ud83e\udde0 MULTI-HOP CONTEXT DISCOVERED ---\")\n",
    "    for res in context_results:\n",
    "        print(f\"Recall: {res['content'][:120]}...\")\n",
    "        if res.get('related_entities'):\n",
    "            print(f\"  \ud83d\udd17 Multi-hop connections: {[e['content'] for e in res['related_entities'][:3]]}\")\n",
    "\n",
    "    # Generate Final Answer\n",
    "    context_text = \" \".join([r['content'] for r in context_results])\n",
    "    prompt = f\"Based on the following context, answer the user query accurately.\\nContext: {context_text}\\nQuery: {user_query}\"\n",
    "    \n",
    "    try:\n",
    "        print(\"\\n--- \u2728 FINAL GRAPHRAG ANSWER ---\")\n",
    "        print(final_answer)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n(LLM synthesis skipped: {e})\")\n",
    "else:\n",
    "    print(\"\\n\u274c No relevant context found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c478f11",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Visualizing the Intelligence\n",
    "A final look at the relationships we've built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "851383de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.visualization import KGVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "viz = KGVisualizer()\n",
    "viz.visualize_network(kg_final, layout=\"spring\", title=\"Skincare Ingredient Intelligence Graph\")\n",
    "plt.show()"
   ]
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
<<<<<<< HEAD
<<<<<<< Updated upstream
 "nbformat_minor": 2
=======
 "nbformat_minor": 5
>>>>>>> Stashed changes
}
=======
 "nbformat_minor": 5
}
>>>>>>> main
