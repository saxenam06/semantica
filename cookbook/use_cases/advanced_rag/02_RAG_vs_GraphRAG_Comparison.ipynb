{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de0a7591",
   "metadata": {},
   "source": [
    "# RAG vs. GraphRAG: Investigative Intelligence Comparison\n",
    "\n",
    "## Overview\n",
    "This notebook provides a rigorous, side-by-side comparison of **Standard RAG (Vector-based)** and **GraphRAG (Graph-based)**, focusing on the Global Intelligence and Security domain.\n",
    "\n",
    "### The Challenge: Navigating Fragmentation\n",
    "In intelligence work, facts are scattered across reports. Vector search often fails to bridge \"semantic gaps\"â€”logical connections between entities that are not physically co-located in text. \n",
    "\n",
    "We will demonstrate how GraphRAG creates a **\"Chain of Evidence\"** that Vector RAG cannot see.\n",
    "\n",
    "### Framework: Semantica\n",
    "We use the [Semantica](https://github.com/Hawksight-AI/semantica) framework to orchestrate common intelligence tasks like entity resolution, conflict detection, and graph-based reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca782326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU semantica networkx matplotlib plotly pandas faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e971d",
   "metadata": {},
   "source": [
    "## 1. Domain Acquisition: Real-World Intelligence gathering\n",
    "We ingest from high-signal feeds to build our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.ingest import WebIngestor, FeedIngestor\n",
    "from semantica.normalize import TextNormalizer\n",
    "\n",
    "normalizer = TextNormalizer()\n",
    "all_content = []\n",
    "\n",
    "# 1. Global News Feeds (RSS) - Using more robust and accessible feeds\n",
    "feeds = [\n",
    "    \"http://feeds.bbci.co.uk/news/world/rss.xml\",\n",
    "    \"https://www.aljazeera.com/xml/rss/all.xml\",\n",
    "    \"https://news.google.com/rss/search?q=site%3Areuters.com&hl=en-US&gl=US&ceid=US%3Aen\" # Reuters workaround\n",
    "]\n",
    "feed_ingestor = FeedIngestor()\n",
    "for f in feeds:\n",
    "    try:\n",
    "        data = feed_ingestor.ingest_feed(f)\n",
    "        items = data.items[:10]\n",
    "        for item in items:\n",
    "            # Fallback chain: content -> description -> title\n",
    "            text = item.content or item.description or item.title\n",
    "            if text:\n",
    "                all_content.append(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to ingest feed {f}: {e}\")\n",
    "\n",
    "# 2. Strategic Overviews (Web) - Using pages with more permissive robots.txt\n",
    "web_urls = [\n",
    "    \"https://www.cia.gov/the-world-factbook/\",\n",
    "    \"https://www.cfr.org/backgrounders\" \n",
    "]\n",
    "web_ingestor = WebIngestor()\n",
    "for url in web_urls:\n",
    "    try:\n",
    "        content = web_ingestor.ingest_url(url)\n",
    "        if content.text:\n",
    "            all_content.append(content.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to ingest URL {url}: {e}\")\n",
    "\n",
    "# Clean and normalize\n",
    "clean_docs = [normalizer.normalize(text) for text in all_content if len(text) > 100] # Increased threshold for higher quality\n",
    "print(f\"Intelligence Knowledge Hub Populated with {len(clean_docs)} reports.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba35952",
   "metadata": {},
   "source": [
    "## 2. Standard Vector RAG Pipeline\n",
    "Linear retrieval via semantic embedding overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedbf41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.core import Semantica\n",
    "from semantica.split import TextSplitter\n",
    "from semantica.vector_store import VectorStore\n",
    "\n",
    "# v_core = Semantica(embedding={\"provider\": \"openai\", \"model\": \"text-embedding-3-small\"})\n",
    "# Using framework defaults which utilize the core.config\n",
    "v_core = Semantica()\n",
    "\n",
    "splitter = TextSplitter(method=\"recursive\", chunk_size=600, chunk_overlap=50)\n",
    "chunks = []\n",
    "for doc in clean_docs[:10]:\n",
    "    chunks.extend(splitter.split(doc))\n",
    "\n",
    "# Initialize Vector Store\n",
    "vs = VectorStore(backend=\"faiss\", dimension=1536) \n",
    "embeddings = v_core.embedding_generator.generate_embeddings([str(c) for c in chunks[:15]])\n",
    "vs.store_vectors(vectors=embeddings, metadata=[{\"text\": str(c)} for c in chunks[:15]])\n",
    "\n",
    "print(f\"Vector RAG ready with {len(chunks[:15])} encoded fragments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1b0cf",
   "metadata": {},
   "source": [
    "## 3. High-Fidelity GraphRAG Pipeline\n",
    "Synthesizing entities and relationships from fragmented reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.kg import GraphBuilder\n",
    "from semantica.deduplication import DuplicateDetector\n",
    "\n",
    "gb = GraphBuilder(merge_entities=True)\n",
    "# We process a subset for demonstration\n",
    "kg = gb.build(sources=[{\"text\": str(c)} for c in chunks[:10]])\n",
    "\n",
    "print(f\"GraphRAG Synthesis Complete: {len(kg.get('entities', []))} entities, {len(kg.get('relationships', []))} relationships.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b97e797",
   "metadata": {},
   "source": [
    "## 4. The Intelligence Challenge: Multi-Hop Inference\n",
    "Standard RAG finds fragments *about* a topic. GraphRAG finds *connections between* topics.\n",
    "\n",
    "Query: **\"Identify high-risk security escalations and their regional implications.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9fcae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.reasoning import InferenceEngine\n",
    "\n",
    "print(\"--- Standard Vector Recall ---\")\n",
    "q_vec = v_core.embedding_generator.generate_embeddings(\"security risks and regional conflict\")\n",
    "v_res = vs.search_vectors(q_vec, k=3)\n",
    "for r in v_res:\n",
    "    print(f\"Recall: {r['metadata']['text'][:120]}...\")\n",
    "\n",
    "print(\"\\n--- Graph Intelligence Reasoning ---\")\n",
    "engine = InferenceEngine(strategy=\"forward\")\n",
    "\n",
    "# Prefix Rule: IF Conflict(?x) AND LocatedIn(?x, ?y) THEN HighRisk(?y)\n",
    "engine.add_rule(\"IF Conflict(?x) AND LocatedIn(?x, ?y) THEN HighRisk(?y)\")\n",
    "\n",
    "# Add facts from extracted KG\n",
    "for rel in kg.get('relationships', []):\n",
    "    source = rel.get('source', '')\n",
    "    target = rel.get('target', '')\n",
    "    rtype = rel.get('type', '').lower()\n",
    "    \n",
    "    if 'locate' in rtype or 'in' in rtype:\n",
    "        engine.add_fact(f\"LocatedIn({source}, {target})\")\n",
    "\n",
    "# Simulated High-Priority Facts for demonstration\n",
    "engine.add_fact(\"Conflict(Political_Internal_Unrest)\")\n",
    "engine.add_fact(\"LocatedIn(Political_Internal_Unrest, Strategic_Region_A)\")\n",
    "\n",
    "# Perform Inference\n",
    "results = engine.forward_chain()\n",
    "for res in results:\n",
    "    print(f\"Inferred: {res.conclusion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5928355c",
   "metadata": {},
   "source": [
    "## 5. Visualizing the Intelligence Landscape\n",
    "Seeing the 'Bridges' between disconnected events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.visualization import KGVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "viz = KGVisualizer()\n",
    "viz.visualize_network(\n",
    "    kg,\n",
    "    output=\"static\",\n",
    "    title=\"Intelligence Connectivity Map\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
