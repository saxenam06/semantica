{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GraphRAG Complete\n",
        "\n",
        "## Overview\n",
        "\n",
        "Next-generation RAG: build knowledge graph, generate embeddings, store in vector database, implement hybrid RAG, and integrate with LLM.\n",
        "\n",
        "## Workflow: Build KG → Generate Embeddings → Vector Store → Hybrid RAG → LLM Integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.ingest import FileIngestor, WebIngestor\n",
        "from semantica.parse import DocumentParser, WebParser\n",
        "from semantica.semantic_extract import NERExtractor, RelationExtractor\n",
        "from semantica.kg import GraphBuilder\n",
        "from semantica.embeddings import EmbeddingGenerator\n",
        "from semantica.vector_store import VectorStore, HybridSearch\n",
        "from semantica.context import ContextRetriever\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Build Knowledge Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_ingestor = FileIngestor()\n",
        "web_ingestor = WebIngestor()\n",
        "document_parser = DocumentParser()\n",
        "web_parser = WebParser()\n",
        "ner_extractor = NERExtractor()\n",
        "relation_extractor = RelationExtractor()\n",
        "builder = GraphBuilder()\n",
        "\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "doc1_file = os.path.join(temp_dir, \"ai_intro.txt\")\n",
        "doc2_file = os.path.join(temp_dir, \"ml_basics.txt\")\n",
        "doc3_file = os.path.join(temp_dir, \"dl_guide.txt\")\n",
        "\n",
        "with open(doc1_file, 'w') as f:\n",
        "    f.write(\"Introduction to AI: Artificial Intelligence is transforming industries. Neural Networks are key components.\")\n",
        "with open(doc2_file, 'w') as f:\n",
        "    f.write(\"Machine Learning Basics: ML algorithms learn from data patterns. Neural Networks enable complex learning.\")\n",
        "with open(doc3_file, 'w') as f:\n",
        "    f.write(\"Deep Learning Guide: Deep neural networks enable complex learning. Backpropagation is used for training.\")\n",
        "\n",
        "file_objects = []\n",
        "for doc_file in [doc1_file, doc2_file, doc3_file]:\n",
        "    file_obj = file_ingestor.ingest_file(doc_file, read_content=True)\n",
        "    if file_obj:\n",
        "        file_objects.append(file_obj)\n",
        "\n",
        "parsed_documents = []\n",
        "for file_obj in file_objects:\n",
        "    parsed = document_parser.extract_text(file_obj.path)\n",
        "    parsed_documents.append({\n",
        "        \"file\": file_obj.name,\n",
        "        \"content\": parsed,\n",
        "        \"metadata\": file_obj.metadata\n",
        "    })\n",
        "\n",
        "all_entities = []\n",
        "all_relationships = []\n",
        "entity_map = {}\n",
        "\n",
        "for i, doc in enumerate(parsed_documents, 1):\n",
        "    doc_id = f\"doc{i}\"\n",
        "    doc_name = doc[\"file\"].replace(\".txt\", \"\").replace(\"_\", \" \").title()\n",
        "    \n",
        "    all_entities.append({\n",
        "        \"id\": doc_id,\n",
        "        \"type\": \"Document\",\n",
        "        \"name\": doc_name,\n",
        "        \"properties\": {\"content\": doc[\"content\"][:100]}\n",
        "    })\n",
        "    \n",
        "    extracted_entities = ner_extractor.extract(doc[\"content\"])\n",
        "    extracted_relations = relation_extractor.extract(doc[\"content\"], extracted_entities)\n",
        "    \n",
        "    for entity in extracted_entities[:5]:\n",
        "        entity_text = entity.get(\"text\", entity.get(\"entity\", \"\"))\n",
        "        if entity_text and entity_text not in entity_map:\n",
        "            entity_id = f\"concept_{len(entity_map) + 1}\"\n",
        "            entity_map[entity_text] = entity_id\n",
        "            all_entities.append({\n",
        "                \"id\": entity_id,\n",
        "                \"type\": entity.get(\"type\", \"Concept\"),\n",
        "                \"name\": entity_text,\n",
        "                \"properties\": {}\n",
        "            })\n",
        "            \n",
        "            all_relationships.append({\n",
        "                \"source\": doc_id,\n",
        "                \"target\": entity_id,\n",
        "                \"type\": \"mentions\"\n",
        "            })\n",
        "    \n",
        "    for rel in extracted_relations[:3]:\n",
        "        source_text = rel.get(\"source\", \"\")\n",
        "        target_text = rel.get(\"target\", \"\")\n",
        "        if source_text in entity_map and target_text in entity_map:\n",
        "            all_relationships.append({\n",
        "                \"source\": entity_map[source_text],\n",
        "                \"target\": entity_map[target_text],\n",
        "                \"type\": rel.get(\"type\", \"related_to\")\n",
        "            })\n",
        "\n",
        "knowledge_graph = builder.build(all_entities, all_relationships)\n",
        "\n",
        "print(f\"Ingested {len(file_objects)} documents\")\n",
        "print(f\"Extracted {len([e for e in all_entities if e['type'] != 'Document'])} concepts\")\n",
        "print(f\"Built knowledge graph with {len(all_entities)} entities and {len(all_relationships)} relationships\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Generate Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = [doc[\"content\"] for doc in parsed_documents]\n",
        "\n",
        "generator = EmbeddingGenerator()\n",
        "embeddings = generator.generate(documents)\n",
        "\n",
        "print(f\"Generated embeddings for {len(documents)} parsed documents\")\n",
        "print(f\"Embedding dimension: {len(embeddings[0]) if embeddings else 0}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Store in Vector Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store = VectorStore()\n",
        "\n",
        "vector_ids = [f\"doc_{i+1}\" for i in range(len(documents))]\n",
        "metadata = [\n",
        "    {\"doc_id\": \"doc1\", \"topic\": \"AI\", \"type\": \"introduction\"},\n",
        "    {\"doc_id\": \"doc2\", \"topic\": \"ML\", \"type\": \"tutorial\"},\n",
        "    {\"doc_id\": \"doc3\", \"topic\": \"DL\", \"type\": \"guide\"}\n",
        "]\n",
        "\n",
        "vector_ids_stored = vector_store.store_vectors(embeddings, metadata)\n",
        "\n",
        "print(f\"Stored {len(vector_ids_stored)} vectors in vector store\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Hybrid RAG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hybrid_search = HybridSearch()\n",
        "context_retriever = ContextRetriever(\n",
        "    knowledge_graph=knowledge_graph,\n",
        "    vector_store=vector_store\n",
        ")\n",
        "\n",
        "query = \"What is deep learning?\"\n",
        "query_embedding = generator.generate([query])[0]\n",
        "\n",
        "vector_results = vector_store.search_vectors(query_embedding, k=3)\n",
        "\n",
        "graph_context_results = context_retriever.retrieve(\n",
        "    query=query,\n",
        "    max_results=5,\n",
        "    use_graph_expansion=True,\n",
        "    max_hops=2\n",
        ")\n",
        "\n",
        "graph_context = []\n",
        "for result in graph_context_results:\n",
        "    graph_context.append({\n",
        "        \"entity\": result.content,\n",
        "        \"type\": result.metadata.get(\"type\", \"unknown\"),\n",
        "        \"related\": [e.get(\"name\", e.get(\"id\")) for e in result.related_entities[:3]]\n",
        "    })\n",
        "\n",
        "print(f\"Retrieved {len(vector_results)} vector search results\")\n",
        "print(f\"Found {len(graph_context)} relevant graph entities from ContextRetriever\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_context(vector_results, graph_context):\n",
        "    context_parts = []\n",
        "    \n",
        "    context_parts.append(\"Retrieved Documents:\")\n",
        "    for i, result in enumerate(vector_results[:3], 1):\n",
        "        doc_id = result.get(\"id\", \"unknown\")\n",
        "        score = result.get(\"score\", 0)\n",
        "        meta = result.get(\"metadata\", {})\n",
        "        context_parts.append(f\"{i}. Document {doc_id} (relevance: {score:.3f}, topic: {meta.get('topic', 'N/A')})\")\n",
        "    \n",
        "    if graph_context:\n",
        "        context_parts.append(\"\\nKnowledge Graph Context:\")\n",
        "        for ctx in graph_context:\n",
        "            context_parts.append(f\"- {ctx['entity']} ({ctx['type']})\")\n",
        "            if ctx['related']:\n",
        "                context_parts.append(f\"  Related: {', '.join(ctx['related'])}\")\n",
        "    \n",
        "    return \"\\n\".join(context_parts)\n",
        "\n",
        "def generate_response(query, context):\n",
        "    response_template = f\"\"\"\n",
        "Query: {query}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Response: Based on the retrieved context, {query.lower()} is a topic covered in the knowledge base. \n",
        "The relevant documents and graph entities provide comprehensive information about this subject.\n",
        "\"\"\"\n",
        "    return response_template\n",
        "\n",
        "context = format_context(vector_results, graph_context)\n",
        "response = generate_response(query, context)\n",
        "\n",
        "print(\"Generated Response:\")\n",
        "print(response)\n",
        "print(f\"\\nUsed {len(vector_results)} graph-enhanced results\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Next-generation RAG workflow:\n",
        "- Knowledge graph built\n",
        "- Embeddings generated\n",
        "- Vectors stored\n",
        "- Hybrid RAG implemented\n",
        "- LLM integration ready\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
