{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Agent System KG-Powered\n",
        "\n",
        "## Overview\n",
        "\n",
        "AI agent systems: build knowledge graph, implement agent memory, create context graphs, enable multi-agent coordination, and share knowledge.\n",
        "\n",
        "## Workflow: Build KG → Agent Memory → Context Graphs → Multi-Agent Coordination → Shared Knowledge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.ingest import FileIngestor, DBIngestor\n",
        "from semantica.parse import DocumentParser, StructuredDataParser\n",
        "from semantica.semantic_extract import NERExtractor, RelationExtractor\n",
        "from semantica.kg import GraphBuilder\n",
        "from semantica.context import AgentMemory, ContextRetriever\n",
        "from semantica.reasoning import InferenceEngine\n",
        "from datetime import datetime\n",
        "import os\n",
        "import tempfile\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Build Knowledge Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_ingestor = FileIngestor()\n",
        "db_ingestor = DBIngestor()\n",
        "structured_parser = StructuredDataParser()\n",
        "ner_extractor = NERExtractor()\n",
        "relation_extractor = RelationExtractor()\n",
        "builder = GraphBuilder()\n",
        "\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "agents_file = os.path.join(temp_dir, \"agents.json\")\n",
        "tasks_file = os.path.join(temp_dir, \"tasks.json\")\n",
        "\n",
        "agents_data = [\n",
        "    {\"agent_id\": \"agent_1\", \"name\": \"Research Agent\", \"role\": \"researcher\"},\n",
        "    {\"agent_id\": \"agent_2\", \"name\": \"Analysis Agent\", \"role\": \"analyst\"}\n",
        "]\n",
        "\n",
        "tasks_data = [\n",
        "    {\"task_id\": \"task_1\", \"name\": \"Data Collection\", \"status\": \"completed\", \"assigned_to\": \"agent_1\"},\n",
        "    {\"task_id\": \"task_2\", \"name\": \"Data Analysis\", \"status\": \"in_progress\", \"assigned_to\": \"agent_2\"}\n",
        "]\n",
        "\n",
        "with open(agents_file, 'w') as f:\n",
        "    json.dump(agents_data, f)\n",
        "with open(tasks_file, 'w') as f:\n",
        "    json.dump(tasks_data, f)\n",
        "\n",
        "file_objects = file_ingestor.ingest_directory(temp_dir, recursive=False)\n",
        "parsed_agents = structured_parser.parse_json(agents_file)\n",
        "parsed_tasks = structured_parser.parse_json(tasks_file)\n",
        "\n",
        "entities = []\n",
        "relationships = []\n",
        "\n",
        "for agent_data in parsed_agents.get(\"data\", agents_data):\n",
        "    entities.append({\n",
        "        \"id\": agent_data.get(\"agent_id\", \"\"),\n",
        "        \"type\": \"Agent\",\n",
        "        \"name\": agent_data.get(\"name\", \"\"),\n",
        "        \"properties\": {\"role\": agent_data.get(\"role\", \"\")}\n",
        "    })\n",
        "\n",
        "for task_data in parsed_tasks.get(\"data\", tasks_data):\n",
        "    entities.append({\n",
        "        \"id\": task_data.get(\"task_id\", \"\"),\n",
        "        \"type\": \"Task\",\n",
        "        \"name\": task_data.get(\"name\", \"\"),\n",
        "        \"properties\": {\"status\": task_data.get(\"status\", \"\")}\n",
        "    })\n",
        "    \n",
        "    assigned_agent = task_data.get(\"assigned_to\", \"\")\n",
        "    if assigned_agent:\n",
        "        relationships.append({\n",
        "            \"source\": assigned_agent,\n",
        "            \"target\": task_data.get(\"task_id\", \"\"),\n",
        "            \"type\": \"assigned_to\"\n",
        "        })\n",
        "\n",
        "knowledge_content = \"Market Trends: Analysis shows increasing demand in technology sector.\"\n",
        "extracted_entities = ner_extractor.extract(knowledge_content)\n",
        "extracted_relations = relation_extractor.extract(knowledge_content, extracted_entities)\n",
        "\n",
        "for entity in extracted_entities[:3]:\n",
        "    entity_id = f\"knowledge_{len([e for e in entities if e['type'] == 'Knowledge']) + 1}\"\n",
        "    entities.append({\n",
        "        \"id\": entity_id,\n",
        "        \"type\": \"Knowledge\",\n",
        "        \"name\": entity.get(\"text\", entity.get(\"entity\", \"\")),\n",
        "        \"properties\": {}\n",
        "    })\n",
        "    \n",
        "    relationships.append({\n",
        "        \"source\": \"agent_1\",\n",
        "        \"target\": entity_id,\n",
        "        \"type\": \"discovered\"\n",
        "    })\n",
        "    \n",
        "    relationships.append({\n",
        "        \"source\": \"task_1\",\n",
        "        \"target\": entity_id,\n",
        "        \"type\": \"produced\"\n",
        "    })\n",
        "\n",
        "knowledge_graph = builder.build(entities, relationships)\n",
        "\n",
        "print(f\"Ingested {len(file_objects)} files\")\n",
        "print(f\"Parsed {len(parsed_agents.get('data', []))} agents and {len(parsed_tasks.get('data', []))} tasks\")\n",
        "print(f\"Extracted {len([e for e in entities if e['type'] == 'Knowledge'])} knowledge entities\")\n",
        "print(f\"Built knowledge graph with {len(entities)} entities and {len(relationships)} relationships\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Agent Memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_memory = AgentMemory(knowledge_graph=knowledge_graph)\n",
        "\n",
        "agent_experiences = [\n",
        "    {\n",
        "        \"agent_id\": \"agent_1\",\n",
        "        \"content\": \"Completed data collection task successfully\",\n",
        "        \"metadata\": {\"task\": \"task_1\", \"timestamp\": datetime.now().isoformat()}\n",
        "    },\n",
        "    {\n",
        "        \"agent_id\": \"agent_2\",\n",
        "        \"content\": \"Started analyzing collected data\",\n",
        "        \"metadata\": {\"task\": \"task_2\", \"timestamp\": datetime.now().isoformat()}\n",
        "    }\n",
        "]\n",
        "\n",
        "for experience in agent_experiences:\n",
        "    memory_id = agent_memory.store(\n",
        "        content=experience[\"content\"],\n",
        "        metadata=experience[\"metadata\"],\n",
        "        entities=[{\"id\": experience[\"agent_id\"], \"type\": \"Agent\"}]\n",
        "    )\n",
        "    print(f\"Stored experience for {experience['agent_id']}: {memory_id}\")\n",
        "\n",
        "print(f\"\\nTotal memories stored: {agent_memory.stats.get('total_items', 0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Context Graphs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "context_retriever = ContextRetriever(knowledge_graph=knowledge_graph)\n",
        "\n",
        "def get_agent_context(agent_id, query, kg, retriever):\n",
        "    context_query = f\"{query} for agent {agent_id}\"\n",
        "    retrieved_context = retriever.retrieve(\n",
        "        query=context_query,\n",
        "        max_results=5,\n",
        "        use_graph_expansion=True,\n",
        "        max_hops=2,\n",
        "        entity_ids=[agent_id]\n",
        "    )\n",
        "    \n",
        "    context_items = []\n",
        "    if retrieved_context:\n",
        "        context_items.append({\n",
        "            \"type\": \"agent_info\",\n",
        "            \"data\": {\"agent_id\": agent_id}\n",
        "        })\n",
        "        \n",
        "        related_tasks = []\n",
        "        related_knowledge = []\n",
        "        \n",
        "        for ctx in retrieved_context:\n",
        "            for entity in ctx.related_entities:\n",
        "                if entity.get(\"type\") == \"Task\":\n",
        "                    related_tasks.append(entity)\n",
        "                elif entity.get(\"type\") == \"Knowledge\":\n",
        "                    related_knowledge.append(entity)\n",
        "        \n",
        "        context_items.append({\n",
        "            \"type\": \"related_tasks\",\n",
        "            \"data\": related_tasks\n",
        "        })\n",
        "        context_items.append({\n",
        "            \"type\": \"related_knowledge\",\n",
        "            \"data\": related_knowledge\n",
        "        })\n",
        "    \n",
        "    return context_items\n",
        "\n",
        "context_agent_1 = get_agent_context(\"agent_1\", \"What should I work on?\", knowledge_graph, context_retriever)\n",
        "print(f\"Context for agent_1: {len(context_agent_1)} context items\")\n",
        "for item in context_agent_1:\n",
        "    print(f\"  - {item['type']}: {len(item['data']) if isinstance(item['data'], list) else 1} items\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Multi-Agent Coordination\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_knowledge = knowledge_graph\n",
        "\n",
        "task_1 = \"Analyze market trends\"\n",
        "task_2 = \"Review analysis results\"\n",
        "\n",
        "agent_1_context = get_agent_context(\"agent_1\", task_1, shared_knowledge, context_retriever)\n",
        "agent_2_context = get_agent_context(\"agent_2\", task_2, shared_knowledge, context_retriever)\n",
        "\n",
        "print(\"Agent 1 Context:\")\n",
        "for item in agent_1_context:\n",
        "    if isinstance(item['data'], list):\n",
        "        print(f\"  {item['type']}: {[d.get('name', d.get('id')) for d in item['data']]}\")\n",
        "    else:\n",
        "        print(f\"  {item['type']}: {item['data'].get('name', item['data'].get('id'))}\")\n",
        "\n",
        "print(\"\\nAgent 2 Context:\")\n",
        "for item in agent_2_context:\n",
        "    if isinstance(item['data'], list):\n",
        "        print(f\"  {item['type']}: {[d.get('name', d.get('id')) for d in item['data']]}\")\n",
        "    else:\n",
        "        print(f\"  {item['type']}: {item['data'].get('name', item['data'].get('id'))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Shared Knowledge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inference_engine = InferenceEngine()\n",
        "\n",
        "inference_engine.add_rule(\"IF agent performs action ON entity THEN agent action entity\")\n",
        "\n",
        "agent_actions = [\n",
        "    {\"agent\": \"agent_1\", \"action\": \"discovered\", \"entity\": \"knowledge_1\"},\n",
        "    {\"agent\": \"agent_2\", \"action\": \"analyzed\", \"entity\": \"knowledge_1\"},\n",
        "]\n",
        "\n",
        "for action in agent_actions:\n",
        "    inference_engine.add_fact(action)\n",
        "\n",
        "inferred_results = inference_engine.forward_chain()\n",
        "\n",
        "new_relationships = []\n",
        "for action in agent_actions:\n",
        "    new_relationships.append({\n",
        "        \"source\": action[\"agent\"],\n",
        "        \"target\": action[\"entity\"],\n",
        "        \"type\": action[\"action\"],\n",
        "        \"properties\": {\"timestamp\": datetime.now().isoformat(), \"inferred\": False}\n",
        "    })\n",
        "\n",
        "for result in inferred_results:\n",
        "    if hasattr(result, 'conclusion') and isinstance(result.conclusion, dict):\n",
        "        if \"agent\" in result.conclusion and \"entity\" in result.conclusion:\n",
        "            new_relationships.append({\n",
        "                \"source\": result.conclusion.get(\"agent\", \"\"),\n",
        "                \"target\": result.conclusion.get(\"entity\", \"\"),\n",
        "                \"type\": result.conclusion.get(\"action\", \"\"),\n",
        "                \"properties\": {\"timestamp\": datetime.now().isoformat(), \"inferred\": True}\n",
        "            })\n",
        "\n",
        "new_knowledge = {\n",
        "    \"entities\": [],\n",
        "    \"relationships\": new_relationships\n",
        "}\n",
        "\n",
        "if new_knowledge[\"relationships\"]:\n",
        "    updated_kg = builder.build(\n",
        "        knowledge_graph.get(\"entities\", []) + new_knowledge[\"entities\"],\n",
        "        knowledge_graph.get(\"relationships\", []) + new_knowledge[\"relationships\"]\n",
        "    )\n",
        "    print(f\"Updated knowledge graph with {len(new_knowledge['relationships'])} new relationships\")\n",
        "else:\n",
        "    updated_kg = knowledge_graph\n",
        "\n",
        "entities_count = len(updated_kg.get(\"entities\", []))\n",
        "relationships_count = len(updated_kg.get(\"relationships\", []))\n",
        "\n",
        "print(f\"\\nShared knowledge graph has {entities_count} entities and {relationships_count} relationships\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Multi-agent system workflow:\n",
        "- Knowledge graph built\n",
        "- Agent memory implemented\n",
        "- Context graphs created\n",
        "- Multi-agent coordination enabled\n",
        "- Shared knowledge maintained\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
