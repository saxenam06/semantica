{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fraud Detection Anomaly Complete\n",
        "\n",
        "## Overview\n",
        "\n",
        "Production fraud detection: stream transactions, build temporal knowledge graph, detect patterns, identify anomalies, and implement alert system.\n",
        "\n",
        "## Workflow: Stream Transactions → Build Temporal KG → Detect Patterns → Identify Anomalies → Alert System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.ingest import StreamIngestor, FileIngestor\n",
        "from semantica.parse import DocumentParser, StructuredDataParser\n",
        "from semantica.semantic_extract import NERExtractor, RelationExtractor\n",
        "from semantica.kg import GraphBuilder, GraphAnalyzer, TemporalPatternDetector\n",
        "from semantica.reasoning import InferenceEngine\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import os\n",
        "import tempfile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Stream Transactions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stream_ingestor = StreamIngestor()\n",
        "file_ingestor = FileIngestor()\n",
        "structured_parser = StructuredDataParser()\n",
        "\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "transactions_file = os.path.join(temp_dir, \"transactions.json\")\n",
        "\n",
        "transactions_data = [\n",
        "    {\n",
        "        \"transaction_id\": \"txn_001\",\n",
        "        \"user_id\": \"user_123\",\n",
        "        \"amount\": 150.00,\n",
        "        \"merchant\": \"Online Store\",\n",
        "        \"location\": \"New York\",\n",
        "        \"timestamp\": (datetime.now() - timedelta(hours=1)).isoformat(),\n",
        "        \"device\": \"mobile\"\n",
        "    },\n",
        "    {\n",
        "        \"transaction_id\": \"txn_002\",\n",
        "        \"user_id\": \"user_123\",\n",
        "        \"amount\": 2500.00,\n",
        "        \"merchant\": \"Luxury Store\",\n",
        "        \"location\": \"Paris\",\n",
        "        \"timestamp\": (datetime.now() - timedelta(minutes=30)).isoformat(),\n",
        "        \"device\": \"web\"\n",
        "    },\n",
        "    {\n",
        "        \"transaction_id\": \"txn_003\",\n",
        "        \"user_id\": \"user_456\",\n",
        "        \"amount\": 50.00,\n",
        "        \"merchant\": \"Grocery Store\",\n",
        "        \"location\": \"San Francisco\",\n",
        "        \"timestamp\": (datetime.now() - timedelta(minutes=15)).isoformat(),\n",
        "        \"device\": \"mobile\"\n",
        "    },\n",
        "    {\n",
        "        \"transaction_id\": \"txn_004\",\n",
        "        \"user_id\": \"user_123\",\n",
        "        \"amount\": 5000.00,\n",
        "        \"merchant\": \"Electronics Store\",\n",
        "        \"location\": \"Tokyo\",\n",
        "        \"timestamp\": (datetime.now() - timedelta(minutes=5)).isoformat(),\n",
        "        \"device\": \"mobile\"\n",
        "    }\n",
        "]\n",
        "\n",
        "with open(transactions_file, 'w') as f:\n",
        "    json.dump(transactions_data, f)\n",
        "\n",
        "file_objects = file_ingestor.ingest_file(transactions_file, read_content=True)\n",
        "parsed_data = structured_parser.parse_json(transactions_file)\n",
        "\n",
        "transaction_stream = []\n",
        "for txn in parsed_data.get(\"data\", transactions_data):\n",
        "    if isinstance(txn, dict):\n",
        "        txn_copy = txn.copy()\n",
        "        if \"timestamp\" in txn_copy and isinstance(txn_copy[\"timestamp\"], str):\n",
        "            txn_copy[\"timestamp\"] = datetime.fromisoformat(txn_copy[\"timestamp\"])\n",
        "        transaction_stream.append(txn_copy)\n",
        "\n",
        "print(f\"Ingested {len(file_objects)} transaction files\")\n",
        "print(f\"Parsed {len(transaction_stream)} transactions from structured data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Build Temporal Knowledge Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = GraphBuilder()\n",
        "\n",
        "transaction_entities = []\n",
        "relationships = []\n",
        "\n",
        "for txn in transaction_stream:\n",
        "    txn_id = txn[\"transaction_id\"]\n",
        "    user_id = txn[\"user_id\"]\n",
        "    merchant = txn[\"merchant\"]\n",
        "    location = txn[\"location\"]\n",
        "    \n",
        "    transaction_entities.append({\n",
        "        \"id\": txn_id,\n",
        "        \"type\": \"Transaction\",\n",
        "        \"properties\": {\n",
        "            \"amount\": txn[\"amount\"],\n",
        "            \"timestamp\": txn[\"timestamp\"].isoformat(),\n",
        "            \"device\": txn[\"device\"]\n",
        "        }\n",
        "    })\n",
        "    \n",
        "    transaction_entities.append({\n",
        "        \"id\": user_id,\n",
        "        \"type\": \"User\",\n",
        "        \"properties\": {}\n",
        "    })\n",
        "    \n",
        "    transaction_entities.append({\n",
        "        \"id\": merchant,\n",
        "        \"type\": \"Merchant\",\n",
        "        \"properties\": {}\n",
        "    })\n",
        "    \n",
        "    transaction_entities.append({\n",
        "        \"id\": location,\n",
        "        \"type\": \"Location\",\n",
        "        \"properties\": {}\n",
        "    })\n",
        "    \n",
        "    relationships.append({\n",
        "        \"source\": user_id,\n",
        "        \"target\": txn_id,\n",
        "        \"type\": \"performed\",\n",
        "        \"properties\": {\"timestamp\": txn[\"timestamp\"].isoformat()}\n",
        "    })\n",
        "    \n",
        "    relationships.append({\n",
        "        \"source\": txn_id,\n",
        "        \"target\": merchant,\n",
        "        \"type\": \"at_merchant\",\n",
        "        \"properties\": {}\n",
        "    })\n",
        "    \n",
        "    relationships.append({\n",
        "        \"source\": txn_id,\n",
        "        \"target\": location,\n",
        "        \"type\": \"in_location\",\n",
        "        \"properties\": {}\n",
        "    })\n",
        "\n",
        "transaction_kg = builder.build(transaction_entities, relationships)\n",
        "\n",
        "print(f\"Built temporal knowledge graph with {len(transaction_entities)} entities and {len(relationships)} relationships\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Detect Patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inference_engine = InferenceEngine()\n",
        "pattern_detector = TemporalPatternDetector()\n",
        "graph_analyzer = GraphAnalyzer()\n",
        "\n",
        "temporal_patterns = pattern_detector.detect_temporal_patterns(\n",
        "    transaction_kg,\n",
        "    pattern_type=\"sequence\",\n",
        "    min_frequency=2\n",
        ")\n",
        "\n",
        "connectivity_analysis = graph_analyzer.analyze_connectivity(transaction_kg)\n",
        "\n",
        "fraud_patterns = []\n",
        "user_transactions = {}\n",
        "for txn in transaction_stream:\n",
        "    user_id = txn[\"user_id\"]\n",
        "    if user_id not in user_transactions:\n",
        "        user_transactions[user_id] = []\n",
        "    user_transactions[user_id].append(txn)\n",
        "\n",
        "for user_id, txns in user_transactions.items():\n",
        "    if len(txns) > 1:\n",
        "        amounts = [t[\"amount\"] for t in txns]\n",
        "        locations = [t[\"location\"] for t in txns]\n",
        "        timestamps = [t[\"timestamp\"] for t in txns]\n",
        "        \n",
        "        if max(amounts) > 1000:\n",
        "            fraud_patterns.append({\n",
        "                \"type\": \"high_value_transaction\",\n",
        "                \"user_id\": user_id,\n",
        "                \"amount\": max(amounts),\n",
        "                \"severity\": \"medium\"\n",
        "            })\n",
        "        \n",
        "        if len(set(locations)) > 2:\n",
        "            time_span = max(timestamps) - min(timestamps)\n",
        "            if time_span.total_seconds() < 3600:\n",
        "                fraud_patterns.append({\n",
        "                    \"type\": \"rapid_location_change\",\n",
        "                    \"user_id\": user_id,\n",
        "                    \"locations\": list(set(locations)),\n",
        "                    \"severity\": \"high\"\n",
        "                })\n",
        "\n",
        "print(f\"Detected {len(fraud_patterns)} fraud patterns\")\n",
        "print(f\"Temporal patterns: {len(temporal_patterns)}\")\n",
        "print(f\"Connectivity analysis: {connectivity_analysis.get('is_connected', False)}\")\n",
        "for pattern in fraud_patterns:\n",
        "    print(f\"  Pattern: {pattern['type']} - User: {pattern['user_id']} - Severity: {pattern['severity']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Identify Anomalies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anomaly_patterns = pattern_detector.detect_temporal_patterns(\n",
        "    transaction_kg,\n",
        "    pattern_type=\"anomaly\",\n",
        "    min_frequency=1\n",
        ")\n",
        "\n",
        "anomalies = []\n",
        "for txn in transaction_stream:\n",
        "    score = 0\n",
        "    reasons = []\n",
        "    \n",
        "    if txn[\"amount\"] > 2000:\n",
        "        score += 3\n",
        "        reasons.append(\"High transaction amount\")\n",
        "    \n",
        "    if txn[\"amount\"] > 1000 and txn[\"device\"] == \"mobile\":\n",
        "        score += 2\n",
        "        reasons.append(\"High amount on mobile device\")\n",
        "    \n",
        "    user_txns = [t for t in transaction_stream if t[\"user_id\"] == txn[\"user_id\"]]\n",
        "    if len(user_txns) > 1:\n",
        "        recent_txns = sorted(user_txns, key=lambda x: x[\"timestamp\"], reverse=True)[:3]\n",
        "        locations = [t[\"location\"] for t in recent_txns]\n",
        "        if len(set(locations)) > 2:\n",
        "            time_span = recent_txns[0][\"timestamp\"] - recent_txns[-1][\"timestamp\"]\n",
        "            if time_span.total_seconds() < 3600:\n",
        "                score += 4\n",
        "                reasons.append(\"Rapid location changes\")\n",
        "    \n",
        "    if score >= 3:\n",
        "        anomalies.append({\n",
        "            \"transaction_id\": txn[\"transaction_id\"],\n",
        "            \"user_id\": txn[\"user_id\"],\n",
        "            \"severity\": \"high\" if score >= 5 else \"medium\",\n",
        "            \"score\": score,\n",
        "            \"reasons\": reasons,\n",
        "            \"timestamp\": txn[\"timestamp\"]\n",
        "        })\n",
        "\n",
        "print(f\"Detected {len(anomalies)} anomalies\")\n",
        "for anomaly in anomalies:\n",
        "    print(f\"  Transaction: {anomaly['transaction_id']} - Severity: {anomaly['severity']} - Score: {anomaly['score']}\")\n",
        "    print(f\"    Reasons: {', '.join(anomaly['reasons'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Alert System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def send_alert(anomaly):\n",
        "    alert = {\n",
        "        \"alert_id\": f\"alert_{anomaly['transaction_id']}\",\n",
        "        \"transaction_id\": anomaly[\"transaction_id\"],\n",
        "        \"user_id\": anomaly[\"user_id\"],\n",
        "        \"severity\": anomaly[\"severity\"],\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"reasons\": anomaly[\"reasons\"]\n",
        "    }\n",
        "    return alert\n",
        "\n",
        "def log_fraud_event(anomaly):\n",
        "    event = {\n",
        "        \"event_type\": \"fraud_detected\",\n",
        "        \"transaction_id\": anomaly[\"transaction_id\"],\n",
        "        \"user_id\": anomaly[\"user_id\"],\n",
        "        \"severity\": anomaly[\"severity\"],\n",
        "        \"score\": anomaly[\"score\"],\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "    return event\n",
        "\n",
        "threshold = 3\n",
        "alerts = []\n",
        "fraud_events = []\n",
        "\n",
        "for anomaly in anomalies:\n",
        "    if anomaly[\"score\"] >= threshold:\n",
        "        alert = send_alert(anomaly)\n",
        "        alerts.append(alert)\n",
        "        event = log_fraud_event(anomaly)\n",
        "        fraud_events.append(event)\n",
        "\n",
        "print(f\"Generated {len(alerts)} alerts\")\n",
        "for alert in alerts:\n",
        "    print(f\"  Alert: {alert['alert_id']} - Severity: {alert['severity']} - Transaction: {alert['transaction_id']}\")\n",
        "\n",
        "print(f\"\\nLogged {len(fraud_events)} fraud events\")\n",
        "\n",
        "entities_count = len(transaction_kg.get(\"entities\", []))\n",
        "print(f\"\\nMonitoring {entities_count} transaction entities\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Production fraud detection workflow:\n",
        "- Transaction streaming configured\n",
        "- Temporal knowledge graph built\n",
        "- Fraud patterns detected\n",
        "- Anomalies identified\n",
        "- Alert system operational\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
