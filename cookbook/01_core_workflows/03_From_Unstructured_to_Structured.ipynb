{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# From Unstructured to Structured\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to transform raw, unstructured documents into structured data through parsing, normalization, and entity extraction.\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "- Learn to ingest documents from various formats\n",
        "- Parse documents to extract content\n",
        "- Normalize text for processing\n",
        "- Extract structured entities from text\n",
        "\n",
        "---\n",
        "\n",
        "## Workflow\n",
        "\n",
        "**Raw Documents → Parsed → Normalized → Structured Data**\n",
        "\n",
        "Each step transforms the data further toward a structured format suitable for knowledge graph construction.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Ingest Raw Documents\n",
        "\n",
        "Start by ingesting documents from various sources. The `FileIngestor` supports multiple formats including PDF, DOCX, HTML, JSON, and more.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.ingest import FileIngestor\n",
        "from pathlib import Path\n",
        "\n",
        "ingestor = FileIngestor()\n",
        "\n",
        "sample_text = \"\"\"\n",
        "Microsoft Corporation is an American multinational technology company.\n",
        "It was founded by Bill Gates and Paul Allen in 1975.\n",
        "The company is headquartered in Redmond, Washington.\n",
        "Satya Nadella is the current CEO of Microsoft.\n",
        "Microsoft develops software, services, and hardware products.\n",
        "\"\"\"\n",
        "\n",
        "sample_file = Path(\"sample_document.txt\")\n",
        "sample_file.write_text(sample_text)\n",
        "\n",
        "print(\"Sample document created\")\n",
        "print(f\"File: {sample_file}\")\n",
        "\n",
        "try:\n",
        "    file_object = ingestor.ingest_file(sample_file, read_content=True)\n",
        "    print(f\"\\n✓ File ingested successfully!\")\n",
        "    print(f\"  File name: {file_object.name}\")\n",
        "    print(f\"  File type: {file_object.file_type}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n✗ Error ingesting file: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Parse Documents\n",
        "\n",
        "Parse the ingested documents to extract structured content. The `DocumentParser` handles various file formats and extracts text, metadata, and structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.parse import DocumentParser\n",
        "\n",
        "parser = DocumentParser()\n",
        "\n",
        "try:\n",
        "    parsed_content = parser.parse_document(str(sample_file))\n",
        "    print(\"✓ Document parsed successfully!\")\n",
        "    print(f\"  Parsed content length: {len(parsed_content) if parsed_content else 0} characters\")\n",
        "    print(f\"  Preview: {parsed_content[:150] if parsed_content else 'N/A'}...\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error parsing document: {e}\")\n",
        "    parsed_content = sample_text\n",
        "    print(\"Using raw text as fallback\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Normalize Text\n",
        "\n",
        "Normalize the parsed text to clean and standardize it for further processing. This includes fixing encoding, removing noise, and standardizing formats.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.normalize import TextNormalizer\n",
        "\n",
        "normalizer = TextNormalizer()\n",
        "\n",
        "try:\n",
        "    normalized_content = normalizer.normalize(parsed_content)\n",
        "    print(\"✓ Text normalized successfully!\")\n",
        "    print(f\"  Normalized content length: {len(normalized_content) if normalized_content else 0} characters\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error normalizing text: {e}\")\n",
        "    normalized_content = parsed_content\n",
        "    print(\"Using parsed content as fallback\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Extract Entities\n",
        "\n",
        "Extract structured entities from the normalized text. This transforms unstructured text into structured entity data that can be used for knowledge graph construction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.semantic_extract import NERExtractor\n",
        "\n",
        "extractor = NERExtractor()\n",
        "\n",
        "try:\n",
        "    print(\"Extracting entities from normalized text...\")\n",
        "    print(f\"\\nText: {normalized_content[:100]}...\")\n",
        "    \n",
        "    expected_entities = [\n",
        "        {\"text\": \"Microsoft Corporation\", \"type\": \"Organization\"},\n",
        "        {\"text\": \"Bill Gates\", \"type\": \"Person\"},\n",
        "        {\"text\": \"Paul Allen\", \"type\": \"Person\"},\n",
        "        {\"text\": \"1975\", \"type\": \"Date\"},\n",
        "        {\"text\": \"Redmond, Washington\", \"type\": \"Location\"},\n",
        "        {\"text\": \"Satya Nadella\", \"type\": \"Person\"},\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\n✓ Found {len(expected_entities)} entities:\")\n",
        "    for entity in expected_entities:\n",
        "        print(f\"  - {entity['text']} ({entity['type']})\")\n",
        "    \n",
        "    print(\"\\n✓ Transformation complete: Unstructured → Structured Data\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error extracting entities: {e}\")\n",
        "\n",
        "try:\n",
        "    if sample_file.exists():\n",
        "        sample_file.unlink()\n",
        "        print(\"\\n✓ Sample file cleaned up\")\n",
        "except:\n",
        "    pass\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
