{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Semantic Search Pipeline\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates a production-ready semantic search pipeline: process documents, generate embeddings, store in vector database, and retrieve results.\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "- Parse documents for search\n",
        "- Generate embeddings for semantic search\n",
        "- Store embeddings in a vector store\n",
        "- Query and retrieve relevant results\n",
        "\n",
        "---\n",
        "\n",
        "## Workflow\n",
        "\n",
        "**Documents → Embeddings → Vector Store → Query → Results**\n",
        "\n",
        "This complete pipeline enables production-ready semantic search.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Parse Documents\n",
        "\n",
        "Start by parsing documents to extract searchable content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.parse import DocumentParser\n",
        "from pathlib import Path\n",
        "\n",
        "sample_docs = [\n",
        "    \"Python is a high-level programming language.\",\n",
        "    \"JavaScript is used for web development.\",\n",
        "    \"Machine learning algorithms learn from data.\",\n",
        "]\n",
        "\n",
        "parser = DocumentParser()\n",
        "\n",
        "try:\n",
        "    parsed_docs = []\n",
        "    for doc in sample_docs:\n",
        "        parsed = parser.parse_document(doc)\n",
        "        parsed_docs.append(parsed)\n",
        "    \n",
        "    print(f\"✓ Parsed {len(parsed_docs)} documents\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error parsing documents: {e}\")\n",
        "    parsed_docs = sample_docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Generate Embeddings\n",
        "\n",
        "Generate embeddings for the parsed documents to enable semantic search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.embeddings import EmbeddingGenerator\n",
        "import numpy as np\n",
        "\n",
        "generator = EmbeddingGenerator()\n",
        "\n",
        "try:\n",
        "    embeddings = generator.generate(parsed_docs)\n",
        "    print(\"✓ Embeddings generated\")\n",
        "    print(f\"  Documents: {len(parsed_docs)}\")\n",
        "    print(f\"  Embeddings ready for storage\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error generating embeddings: {e}\")\n",
        "    embeddings = np.random.rand(len(parsed_docs), 1536).astype(np.float32)\n",
        "    print(\"  Using demo embeddings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Store in Vector Store\n",
        "\n",
        "Store the embeddings along with documents and metadata in a vector store.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.vector_store import VectorStore\n",
        "\n",
        "vector_store = VectorStore()\n",
        "\n",
        "metadata = [{\"id\": i, \"source\": \"demo\"} for i in range(len(parsed_docs))]\n",
        "\n",
        "try:\n",
        "    vector_store.store(embeddings, parsed_docs, metadata)\n",
        "    print(\"✓ Documents stored in vector store\")\n",
        "    print(f\"  Stored {len(parsed_docs)} documents\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error storing in vector store: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Query and Retrieve\n",
        "\n",
        "Query the vector store and retrieve the most relevant results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.vector_store import VectorRetriever\n",
        "\n",
        "retriever = VectorRetriever(vector_store)\n",
        "\n",
        "query = \"programming language\"\n",
        "query_embedding = generator.generate([query])[0] if hasattr(generator, 'generate') else np.random.rand(1536).astype(np.float32)\n",
        "\n",
        "try:\n",
        "    results = retriever.retrieve(query_embedding, top_k=3)\n",
        "    \n",
        "    print(\"✓ Production-ready semantic search complete\")\n",
        "    print(f\"  Query: '{query}'\")\n",
        "    print(f\"  Found {len(results) if results else 0} results\")\n",
        "    \n",
        "    if results:\n",
        "        print(\"\\nTop Results:\")\n",
        "        for i, result in enumerate(results):\n",
        "            score = result.score if hasattr(result, 'score') else 'N/A'\n",
        "            doc = result.document if hasattr(result, 'document') else 'N/A'\n",
        "            print(f\"  {i+1}. Score: {score}, Document: {doc[:60]}...\")\n",
        "    else:\n",
        "        print(\"  Note: Results would show most semantically similar documents\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error retrieving results: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
