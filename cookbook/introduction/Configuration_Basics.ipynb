{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration Basics\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook teaches you how to configure Semantica using `ConfigManager`, environment variables, and configuration files. Proper configuration is essential for using Semantica effectively.\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "- Understand how to use `ConfigManager` for configuration management\n",
        "- Learn to set and use environment variables\n",
        "- Create and load configuration files (YAML/JSON)\n",
        "- Configure common settings for API keys, models, and processing\n",
        "- Follow best practices for configuration management\n",
        "\n",
        "---\n",
        "\n",
        "## Configuration Methods\n",
        "\n",
        "Semantica supports three main configuration methods:\n",
        "\n",
        "1. **ConfigManager** - Programmatic configuration management\n",
        "2. **Environment Variables** - For sensitive data like API keys\n",
        "3. **Config Files** - YAML or JSON files for structured configuration\n",
        "\n",
        "Each method is demonstrated in the code cells below.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: ConfigManager Basics\n",
        "\n",
        "`ConfigManager` is the primary way to manage configuration in Semantica. It provides a unified interface for loading and accessing configuration values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.core import ConfigManager\n",
        "\n",
        "config_manager = ConfigManager()\n",
        "\n",
        "print(\"ConfigManager initialized successfully!\")\n",
        "print(f\"ConfigManager instance: {config_manager}\")\n",
        "\n",
        "try:\n",
        "    print(\"\\nAccessing configuration values:\")\n",
        "    print(\"  Use config_manager.get('path.to.config', default='default_value')\")\n",
        "    print(\"  Example: config_manager.get('llm_provider.provider', default='openai')\")\n",
        "except Exception as e:\n",
        "    print(f\"Error accessing config: {e}\")\n",
        "\n",
        "try:\n",
        "    config = config_manager.config\n",
        "    print(f\"\\n✓ Config object created: {config is not None}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating config object: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Environment Variables\n",
        "\n",
        "Environment variables are the recommended way to store sensitive information like API keys. They're secure and don't get committed to version control.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"Environment Variables (SEMANTICA_*):\")\n",
        "semantica_env_vars = {k: v for k, v in os.environ.items() if k.startswith('SEMANTICA_')}\n",
        "if semantica_env_vars:\n",
        "    for key, value in semantica_env_vars.items():\n",
        "        masked_value = value[:4] + \"...\" if len(value) > 4 else \"***\"\n",
        "        print(f\"  {key} = {masked_value}\")\n",
        "else:\n",
        "    print(\"  No SEMANTICA_* environment variables found\")\n",
        "    print(\"  To set: os.environ['SEMANTICA_API_KEY'] = 'your_key'\")\n",
        "\n",
        "api_key = os.getenv(\"SEMANTICA_API_KEY\")\n",
        "model_name = os.getenv(\"SEMANTICA_MODEL_NAME\", \"default-model\")\n",
        "\n",
        "print(f\"\\nRetrieved values:\")\n",
        "print(f\"  API Key set: {api_key is not None}\")\n",
        "print(f\"  Model name: {model_name}\")\n",
        "\n",
        "print(\"\\nNote: Environment variables with SEMANTICA_ prefix\")\n",
        "print(\"  are automatically loaded by ConfigManager\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Configuration Files\n",
        "\n",
        "Configuration files (YAML or JSON) are great for storing non-sensitive settings like model names, batch sizes, and processing parameters. They provide a structured way to manage configuration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "sample_config_yaml = \"\"\"\n",
        "# Semantica Configuration File\n",
        "api_keys:\n",
        "  openai: your_openai_key_here\n",
        "  anthropic: your_anthropic_key_here\n",
        "\n",
        "llm_provider:\n",
        "  provider: openai\n",
        "  model: gpt-4\n",
        "  temperature: 0.7\n",
        "\n",
        "embedding:\n",
        "  provider: openai\n",
        "  model: text-embedding-3-large\n",
        "  dimensions: 3072\n",
        "\n",
        "knowledge_graph:\n",
        "  backend: networkx\n",
        "  temporal: true\n",
        "\n",
        "processing:\n",
        "  batch_size: 32\n",
        "  max_workers: 4\n",
        "\n",
        "logging:\n",
        "  level: INFO\n",
        "  file: semantica.log\n",
        "\"\"\"\n",
        "\n",
        "config_yaml_path = Path(\"sample_config.yaml\")\n",
        "config_yaml_path.write_text(sample_config_yaml)\n",
        "\n",
        "print(\"Sample config.yaml created:\")\n",
        "print(f\"  Path: {config_yaml_path}\")\n",
        "print(\"\\nConfig file contents:\")\n",
        "print(sample_config_yaml)\n",
        "\n",
        "try:\n",
        "    config_from_file = config_manager.load_from_file(str(config_yaml_path))\n",
        "    print(\"\\n✓ Configuration loaded from YAML file!\")\n",
        "    print(f\"  Config object: {config_from_file is not None}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n✗ Error loading config file: {e}\")\n",
        "\n",
        "sample_config_json = {\n",
        "    \"api_keys\": {\n",
        "        \"openai\": \"your_openai_key_here\",\n",
        "        \"anthropic\": \"your_anthropic_key_here\"\n",
        "    },\n",
        "    \"llm_provider\": {\n",
        "        \"provider\": \"openai\",\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"temperature\": 0.7\n",
        "    },\n",
        "    \"embedding\": {\n",
        "        \"provider\": \"openai\",\n",
        "        \"model\": \"text-embedding-3-large\",\n",
        "        \"dimensions\": 3072\n",
        "    }\n",
        "}\n",
        "\n",
        "config_json_path = Path(\"sample_config.json\")\n",
        "with open(config_json_path, 'w') as f:\n",
        "    json.dump(sample_config_json, f, indent=2)\n",
        "\n",
        "print(f\"\\n✓ Sample config.json created: {config_json_path}\")\n",
        "print(\"\\nNote: ConfigManager can load from both YAML and JSON files\")\n",
        "print(\"  config_manager.load_from_file('config.yaml')\")\n",
        "print(\"  config_manager.load_from_file('config.json')\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Common Settings\n",
        "\n",
        "This section covers the most commonly used configuration settings, including API keys, model parameters, embedding settings, and processing options.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.core import Config\n",
        "\n",
        "print(\"Common Configuration Settings:\")\n",
        "print(\"\\n1. API Keys:\")\n",
        "print(\"   - OpenAI API key\")\n",
        "print(\"   - Anthropic API key\")\n",
        "print(\"   - Cohere API key\")\n",
        "print(\"   - Other provider keys\")\n",
        "\n",
        "print(\"\\n2. Model Names and Parameters:\")\n",
        "print(\"   - LLM provider (openai, anthropic, etc.)\")\n",
        "print(\"   - Model name (gpt-4, claude-3, etc.)\")\n",
        "print(\"   - Temperature, max_tokens, etc.\")\n",
        "\n",
        "print(\"\\n3. Embedding Settings:\")\n",
        "print(\"   - Embedding provider\")\n",
        "print(\"   - Embedding model\")\n",
        "print(\"   - Embedding dimensions\")\n",
        "\n",
        "print(\"\\n4. Graph Database Connections:\")\n",
        "print(\"   - Backend (networkx, neo4j, arangodb)\")\n",
        "print(\"   - Connection strings\")\n",
        "print(\"   - Temporal graph settings\")\n",
        "\n",
        "print(\"\\n5. Logging Levels:\")\n",
        "print(\"   - DEBUG, INFO, WARNING, ERROR\")\n",
        "print(\"   - Log file paths\")\n",
        "\n",
        "print(\"\\n6. Cache Settings:\")\n",
        "print(\"   - Enable/disable caching\")\n",
        "print(\"   - Cache directory\")\n",
        "\n",
        "try:\n",
        "    custom_config_dict = {\n",
        "        \"llm_provider\": {\n",
        "            \"provider\": \"openai\",\n",
        "            \"model\": \"gpt-4\",\n",
        "            \"temperature\": 0.7\n",
        "        },\n",
        "        \"embedding\": {\n",
        "            \"provider\": \"openai\",\n",
        "            \"model\": \"text-embedding-3-large\",\n",
        "            \"dimensions\": 3072\n",
        "        },\n",
        "        \"processing\": {\n",
        "            \"batch_size\": 32,\n",
        "            \"max_workers\": 4\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    custom_config = Config(config_dict=custom_config_dict)\n",
        "    print(\"\\n✓ Custom Config object created with settings:\")\n",
        "    print(f\"  LLM Provider: {custom_config.llm_provider.get('provider', 'N/A')}\")\n",
        "    print(f\"  Embedding Provider: {custom_config.embedding_model.get('provider', 'N/A')}\")\n",
        "    print(f\"  Batch Size: {custom_config.processing.get('batch_size', 'N/A')}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n✗ Error creating custom config: {e}\")\n",
        "\n",
        "try:\n",
        "    if config_yaml_path.exists():\n",
        "        config_yaml_path.unlink()\n",
        "    if config_json_path.exists():\n",
        "        config_json_path.unlink()\n",
        "    print(\"\\n✓ Sample config files cleaned up\")\n",
        "except:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Best Practices\n",
        "\n",
        "Follow these best practices to ensure secure, maintainable, and effective configuration management.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Configuration Best Practices:\")\n",
        "print(\"\\n1. Use Environment Variables for Sensitive Data:\")\n",
        "print(\"   - Never commit API keys to version control\")\n",
        "print(\"   - Use environment variables or secret management\")\n",
        "print(\"   - Example: export SEMANTICA_API_KEY=your_key\")\n",
        "\n",
        "print(\"\\n2. Use Config Files for Non-Sensitive Settings:\")\n",
        "print(\"   - Store model names, batch sizes, etc. in config files\")\n",
        "print(\"   - Use YAML for readability or JSON for compatibility\")\n",
        "print(\"   - Keep config files in version control (without secrets)\")\n",
        "\n",
        "print(\"\\n3. Configuration Hierarchy:\")\n",
        "print(\"   - Environment variables override config file values\")\n",
        "print(\"   - Config file values override defaults\")\n",
        "print(\"   - Use defaults as fallback\")\n",
        "\n",
        "print(\"\\n4. Validate Configuration:\")\n",
        "print(\"   - Check required settings are present\")\n",
        "print(\"   - Validate API keys are set before use\")\n",
        "print(\"   - Use ConfigManager validation features\")\n",
        "\n",
        "print(\"\\n5. Separate Configurations by Environment:\")\n",
        "print(\"   - Development: dev_config.yaml\")\n",
        "print(\"   - Production: prod_config.yaml\")\n",
        "print(\"   - Testing: test_config.yaml\")\n",
        "\n",
        "print(\"\\n6. Document Configuration Options:\")\n",
        "print(\"   - Document all available settings\")\n",
        "print(\"   - Provide examples and defaults\")\n",
        "print(\"   - Explain the impact of each setting\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Example: Checking if required configuration is set\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "required_settings = [\n",
        "    (\"API Key\", os.getenv(\"SEMANTICA_API_KEY\")),\n",
        "    (\"Model Name\", os.getenv(\"SEMANTICA_MODEL_NAME\", \"default\")),\n",
        "]\n",
        "\n",
        "print(\"\\nRequired Settings Status:\")\n",
        "for setting_name, value in required_settings:\n",
        "    status = \"✓ Set\" if value and value != \"default\" else \"✗ Not Set\"\n",
        "    print(f\"  {setting_name}: {status}\")\n",
        "\n",
        "print(\"\\nRecommendation:\")\n",
        "print(\"  Set up your configuration before running Semantica workflows\")\n",
        "print(\"  Use ConfigManager to load and validate your settings\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
