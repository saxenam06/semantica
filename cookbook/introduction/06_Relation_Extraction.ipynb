{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hawksight-AI/semantica/blob/main/cookbook/introduction/06_Relation_Extraction.ipynb)\n",
    "\n",
    "#  Relation Extraction - Comprehensive Guide\n",
    "\n",
    "##  Overview\n",
    "\n",
    "This notebook provides a **comprehensive guide** to extracting relationships between entities and building RDF triplets using Semantica's relation extraction modules. You'll learn to identify connections, extract structured triplets, and prepare data for knowledge graphs.\n",
    "\n",
    "**Documentation**: [API Reference](https://semantica.readthedocs.io/reference/semantic_extract/)\n",
    "\n",
    "###  Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "-  Extract relationships using `RelationExtractor`\n",
    "-  Understand different extraction methods (pattern, dependency, co-occurrence, HuggingFace, LLM)\n",
    "-  Configure extraction parameters for optimal results\n",
    "-  Extract RDF triplets with `TripletExtractor`\n",
    "-  Validate triplets using `TripletValidator`\n",
    "-  Serialize triplets to RDF formats with `RDFSerializer`\n",
    "-  Assess triplet quality with `TripletQualityChecker`\n",
    "-  Build complete entity \u2192 relation \u2192 triplet pipelines\n",
    "\n",
    "###  What You'll Learn\n",
    "\n",
    "| Component | Purpose | When to Use |\n",
    "|-----------|---------|-------------|\n",
    "| `RelationExtractor` | Extract entity relationships | Finding connections |\n",
    "| `TripletExtractor` | Extract RDF triplets | Building knowledge graphs |\n",
    "| `TripletValidator` | Validate triplet quality | Quality assurance |\n",
    "| `RDFSerializer` | Serialize to RDF formats | Data export |\n",
    "| `TripletQualityChecker` | Assess triplet quality | Quality metrics |\n",
    "\n",
    "---\n",
    "\n",
    "##  Installation\n",
    "\n",
    "Install Semantica from PyPI:\n",
    "\n",
    "```bash\n",
    "pip install semantica\n",
    "# Or with all optional dependencies:\n",
    "pip install semantica[all]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install semantica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 1: Basic Relation Extraction\n",
    "\n",
    "Let's start by extracting relationships between entities using `RelationExtractor`.\n",
    "\n",
    "### What is RelationExtractor?\n",
    "\n",
    "`RelationExtractor` identifies relationships between entities:\n",
    "- Finds connections like \"founded_by\", \"located_in\", \"works_for\"\n",
    "- Returns Relation objects with subject, predicate, object\n",
    "- Supports multiple extraction methods\n",
    "- Provides confidence scores for each relation\n",
    "\n",
    "### Understanding Relations\n",
    "\n",
    "A relation has three parts:\n",
    "- **Subject**: The source entity (e.g., \"Apple Inc.\")\n",
    "- **Predicate**: The relationship type (e.g., \"founded_by\")\n",
    "- **Object**: The target entity (e.g., \"Steve Jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.semantic_extract import RelationExtractor, NERExtractor\n",
    "\n",
    "# Initialize extractors\n",
    "ner_extractor = NERExtractor()\n",
    "relation_extractor = RelationExtractor()\n",
    "\n",
    "# Sample text with clear relationships\n",
    "text = \"\"\"\n",
    "Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in 1976.\n",
    "The company is headquartered in Cupertino, California. Tim Cook is the current CEO\n",
    "of Apple Inc. and took over from Steve Jobs in August 2011.\n",
    "\"\"\"\n",
    "\n",
    "# First, extract entities\n",
    "entities = ner_extractor.extract(text)\n",
    "print(f\" Extracted {len(entities)} entities\\n\")\n",
    "\n",
    "# Then, extract relationships\n",
    "relationships = relation_extractor.extract(text, entities)\n",
    "\n",
    "print(f\" Extracted {len(relationships)} relationships:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, rel in enumerate(relationships, 1):\n",
    "    # Handle both dict and object formats\n",
    "    source = rel.get('source', rel.get('subject', '')) if isinstance(rel, dict) else getattr(rel, 'subject', '')\n",
    "    target = rel.get('target', rel.get('object', '')) if isinstance(rel, dict) else getattr(rel, 'object', '')\n",
    "    rel_type = rel.get('type', rel.get('predicate', 'related_to')) if isinstance(rel, dict) else getattr(rel, 'predicate', 'related_to')\n",
    "    confidence = rel.get('confidence', 1.0) if isinstance(rel, dict) else getattr(rel, 'confidence', 1.0)\n",
    "    \n",
    "    # Get source and target text\n",
    "    if isinstance(source, dict):\n",
    "        source_text = source.get('text', source.get('entity', str(source)))\n",
    "    else:\n",
    "        source_text = getattr(source, 'text', str(source))\n",
    "    \n",
    "    if isinstance(target, dict):\n",
    "        target_text = target.get('text', target.get('entity', str(target)))\n",
    "    else:\n",
    "        target_text = getattr(target, 'text', str(target))\n",
    "    \n",
    "    print(f\"{i:2d}. {source_text:20s} --[{rel_type:15s}]--> {target_text:20s} (conf: {confidence:.2f})\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Understanding Relation Objects\n",
    "\n",
    "Each extracted relation contains:\n",
    "\n",
    "| Attribute | Description | Example |\n",
    "|-----------|-------------|----------|\n",
    "| `subject` | Source entity | Entity(\"Apple Inc.\") |\n",
    "| `predicate` | Relationship type | \"founded_by\" |\n",
    "| `object` | Target entity | Entity(\"Steve Jobs\") |\n",
    "| `confidence` | Extraction confidence (0-1) | 0.85 |\n",
    "| `context` | Surrounding text | \"Apple Inc. was founded by Steve Jobs\" |\n",
    "| `metadata` | Additional info | {\"method\": \"pattern\"} |\n",
    "\n",
    "###  Common Relation Types\n",
    "\n",
    "- **founded_by**: Organization founded by person\n",
    "- **located_in**: Entity located in place\n",
    "- **works_for**: Person works for organization\n",
    "- **born_in**: Person born in location\n",
    "- **part_of**: Entity is part of another\n",
    "- **related_to**: Generic relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ufe0f Step 2: Different Extraction Methods\n",
    "\n",
    "Semantica supports multiple relation extraction methods:\n",
    "\n",
    "### Method Comparison\n",
    "\n",
    "| Method | Speed | Accuracy | Use Case | Requires |\n",
    "|--------|-------|----------|----------|----------|\n",
    "| **pattern** |  | \u2b50\u2b50\u2b50 | Common relations | Nothing |\n",
    "| **dependency** |  | \u2b50\u2b50\u2b50\u2b50 | Grammatical relations | spaCy |\n",
    "| **cooccurrence** |  | \u2b50\u2b50 | Proximity-based | Nothing |\n",
    "| **huggingface** |  | \u2b50\u2b50\u2b50\u2b50\u2b50 | Domain-specific | HF model |\n",
    "| **llm** |  | \u2b50\u2b50\u2b50\u2b50\u2b50 | Complex, custom | API key |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.semantic_extract import RelationExtractor\n",
    "\n",
    "sample_text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California.\"\n",
    "sample_entities = ner_extractor.extract(sample_text)\n",
    "\n",
    "print(\" Comparing Relation Extraction Methods:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Try different methods\n",
    "methods_to_try = [\"pattern\", \"dependency\", \"cooccurrence\"]\n",
    "\n",
    "for method_name in methods_to_try:\n",
    "    try:\n",
    "        print(f\"\\n Method: {method_name.upper()}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        extractor = RelationExtractor(method=method_name)\n",
    "        relations = extractor.extract(sample_text, sample_entities)\n",
    "        \n",
    "        print(f\"Found {len(relations)} relations:\")\n",
    "        for rel in relations[:3]:  # Show first 3\n",
    "            source = rel.get('source', rel.get('subject', '')) if isinstance(rel, dict) else getattr(rel, 'subject', '')\n",
    "            target = rel.get('target', rel.get('object', '')) if isinstance(rel, dict) else getattr(rel, 'object', '')\n",
    "            rel_type = rel.get('type', rel.get('predicate', 'related_to')) if isinstance(rel, dict) else getattr(rel, 'predicate', 'related_to')\n",
    "            \n",
    "            # Get text representations\n",
    "            source_text = source.get('text', str(source)) if isinstance(source, dict) else getattr(source, 'text', str(source))\n",
    "            target_text = target.get('text', str(target)) if isinstance(target, dict) else getattr(target, 'text', str(target))\n",
    "            \n",
    "            print(f\"  \u2022 {source_text} --[{rel_type}]--> {target_text}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  \ufe0f  Method '{method_name}' not available: {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 3: Advanced Relation Extraction with Configuration\n",
    "\n",
    "`RelationExtractor` provides powerful configuration options:\n",
    "\n",
    "### Key Parameters:\n",
    "\n",
    "- **`relation_types`**: Specific relation types to extract (e.g., `[\"founded\", \"works_at\"]`)\n",
    "- **`bidirectional`**: Extract bidirectional relations (default: False)\n",
    "- **`confidence_threshold`**: Minimum confidence score (0.0-1.0, default: 0.6)\n",
    "- **`max_distance`**: Maximum token distance between entities (default: 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extractor with custom configuration\n",
    "advanced_extractor = RelationExtractor(\n",
    "    relation_types=[\"founded_by\", \"located_in\", \"works_for\"],  # Only extract these types\n",
    "    confidence_threshold=0.7,  # Higher threshold for quality\n",
    "    bidirectional=False,  # One-way relations only\n",
    "    max_distance=50  # Max 50 tokens between entities\n",
    ")\n",
    "\n",
    "# Sample texts\n",
    "texts = [\n",
    "    \"Microsoft was founded by Bill Gates and Paul Allen in Albuquerque, New Mexico.\",\n",
    "    \"Satya Nadella works for Microsoft as the CEO.\",\n",
    "    \"Google is located in Mountain View, California.\",\n",
    "    \"Amazon was founded by Jeff Bezos in Seattle, Washington.\"\n",
    "]\n",
    "\n",
    "print(\" Advanced Relation Extraction:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, text in enumerate(texts, 1):\n",
    "    entities = ner_extractor.extract(text)\n",
    "    relations = advanced_extractor.extract(text, entities)\n",
    "    \n",
    "    print(f\"\\n Text {i}: {text}\")\n",
    "    print(f\"   Relations found: {len(relations)}\")\n",
    "    \n",
    "    for rel in relations:\n",
    "        source = rel.get('source', rel.get('subject', '')) if isinstance(rel, dict) else getattr(rel, 'subject', '')\n",
    "        target = rel.get('target', rel.get('object', '')) if isinstance(rel, dict) else getattr(rel, 'object', '')\n",
    "        rel_type = rel.get('type', rel.get('predicate', 'related_to')) if isinstance(rel, dict) else getattr(rel, 'predicate', 'related_to')\n",
    "        confidence = rel.get('confidence', 1.0) if isinstance(rel, dict) else getattr(rel, 'confidence', 1.0)\n",
    "        \n",
    "        source_text = source.get('text', str(source)) if isinstance(source, dict) else getattr(source, 'text', str(source))\n",
    "        target_text = target.get('text', str(target)) if isinstance(target, dict) else getattr(target, 'text', str(target))\n",
    "        \n",
    "        print(f\"     \u2022 {source_text} --[{rel_type}]--> {target_text} (conf: {confidence:.2f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ufe0f Step 4: Relation Classification\n",
    "\n",
    "Group and classify extracted relations by their predicate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relations from all texts\n",
    "all_relations = []\n",
    "for text in texts:\n",
    "    entities = ner_extractor.extract(text)\n",
    "    relations = advanced_extractor.extract(text, entities)\n",
    "    all_relations.extend(relations)\n",
    "\n",
    "# Classify relations\n",
    "classified_relations = advanced_extractor.classify_relations(all_relations)\n",
    "\n",
    "print(\"\ufe0f  Relation Classification:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for rel_type, rel_list in sorted(classified_relations.items()):\n",
    "    print(f\"\\n{rel_type.upper()} ({len(rel_list)} relations):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for rel in rel_list:\n",
    "        source = rel.get('source', rel.get('subject', '')) if isinstance(rel, dict) else getattr(rel, 'subject', '')\n",
    "        target = rel.get('target', rel.get('object', '')) if isinstance(rel, dict) else getattr(rel, 'object', '')\n",
    "        \n",
    "        source_text = source.get('text', str(source)) if isinstance(source, dict) else getattr(source, 'text', str(source))\n",
    "        target_text = target.get('text', str(target)) if isinstance(target, dict) else getattr(target, 'text', str(target))\n",
    "        \n",
    "        print(f\"  \u2022 {source_text} \u2192 {target_text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 5: Triplet Extraction\n",
    "\n",
    "Extract RDF triplets using `TripletExtractor`. Triplets are the foundation of knowledge graphs.\n",
    "\n",
    "### What are RDF Triplets?\n",
    "\n",
    "RDF (Resource Description Framework) triplets are statements with three parts:\n",
    "- **Subject**: What we're talking about\n",
    "- **Predicate**: The property or relationship\n",
    "- **Object**: The value or target\n",
    "\n",
    "Example: `(Apple Inc., founded_by, Steve Jobs)`\n",
    "\n",
    "### Why Use Triplets?\n",
    "\n",
    "- **Standardized format** for knowledge representation\n",
    "- **Compatible** with RDF databases and semantic web\n",
    "- **Queryable** using SPARQL\n",
    "- **Interoperable** across systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.semantic_extract import TripletExtractor\n",
    "\n",
    "# Initialize triplet extractor\n",
    "triplet_extractor = TripletExtractor(\n",
    "    include_temporal=True,  # Include temporal information\n",
    "    include_provenance=True  # Track source sentences\n",
    ")\n",
    "\n",
    "# Sample text\n",
    "triplet_text = \"\"\"\n",
    "Apple Inc. was founded by Steve Jobs in 1976. The company is based in Cupertino, California.\n",
    "Tim Cook became CEO in 2011. Apple develops the iPhone and MacBook products.\n",
    "\"\"\"\n",
    "\n",
    "# Extract triplets\n",
    "triplets = triplet_extractor.extract_triplets(triplet_text)\n",
    "\n",
    "print(f\" Extracted {len(triplets)} RDF Triplets:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, triplet in enumerate(triplets, 1):\n",
    "    subject = triplet.get('subject', '') if isinstance(triplet, dict) else triplet.subject\n",
    "    predicate = triplet.get('predicate', '') if isinstance(triplet, dict) else triplet.predicate\n",
    "    obj = triplet.get('object', '') if isinstance(triplet, dict) else triplet.object\n",
    "    confidence = triplet.get('confidence', 1.0) if isinstance(triplet, dict) else getattr(triplet, 'confidence', 1.0)\n",
    "    \n",
    "    print(f\"{i:2d}. ({subject}, {predicate}, {obj})\")\n",
    "    print(f\"    Confidence: {confidence:.2f}\")\n",
    "    \n",
    "    # Show temporal info if available\n",
    "    metadata = triplet.get('metadata', {}) if isinstance(triplet, dict) else getattr(triplet, 'metadata', {})\n",
    "    if metadata.get('temporal'):\n",
    "        print(f\"    Temporal: {metadata['temporal']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 6: Triplet Validation\n",
    "\n",
    "Validate extracted triplets using `TripletValidator` and assess quality with `TripletQualityChecker`.\n",
    "\n",
    "### Why Validate Triplets?\n",
    "\n",
    "- **Ensure completeness**: All parts (subject, predicate, object) present\n",
    "- **Check confidence**: Filter low-quality extractions\n",
    "- **Verify consistency**: No contradictory statements\n",
    "- **Assess quality**: Overall extraction quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.semantic_extract import TripletValidator, TripletQualityChecker\n",
    "\n",
    "# Initialize validator and quality checker\n",
    "validator = TripletValidator()\n",
    "quality_checker = TripletQualityChecker()\n",
    "\n",
    "print(\" Triplet Validation:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Validate triplets\n",
    "valid_triplets = validator.validate_triplets(triplets, min_confidence=0.5)\n",
    "\n",
    "print(f\"\\n Validation Results:\")\n",
    "print(f\"   Total triplets: {len(triplets)}\")\n",
    "print(f\"   Valid triplets: {len(valid_triplets)}\")\n",
    "print(f\"   Filtered out: {len(triplets) - len(valid_triplets)}\")\n",
    "\n",
    "# Check quality\n",
    "quality_scores = quality_checker.calculate_quality_scores(valid_triplets)\n",
    "\n",
    "print(f\"\\n Quality Metrics:\")\n",
    "print(\"-\" * 40)\n",
    "for metric, value in quality_scores.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   {metric}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"   {metric}: {value}\")\n",
    "\n",
    "# Check consistency\n",
    "consistency_report = validator.check_triplet_consistency(valid_triplets)\n",
    "\n",
    "print(f\"\\n Consistency Check:\")\n",
    "print(f\"   Consistent: {consistency_report.get('consistent', True)}\")\n",
    "print(f\"   Issues found: {len(consistency_report.get('issues', []))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 7: RDF Serialization\n",
    "\n",
    "Serialize triplets to various RDF formats using `RDFSerializer`.\n",
    "\n",
    "### Supported Formats:\n",
    "\n",
    "| Format | Extension | Use Case |\n",
    "|--------|-----------|----------|\n",
    "| **Turtle** | .ttl | Human-readable, compact |\n",
    "| **N-Triples** | .nt | Simple, line-based |\n",
    "| **JSON-LD** | .jsonld | Web-friendly, JSON-based |\n",
    "| **RDF/XML** | .rdf | XML-based, verbose |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.semantic_extract import RDFSerializer\n",
    "\n",
    "# Initialize serializer\n",
    "serializer = RDFSerializer()\n",
    "\n",
    "print(\" RDF Serialization Examples:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Serialize to different formats\n",
    "formats = [\"turtle\", \"ntriples\", \"jsonld\"]\n",
    "\n",
    "for fmt in formats:\n",
    "    print(f\"\\n {fmt.upper()} Format:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        serialized = serializer.serialize_to_rdf(valid_triplets[:3], format=fmt)  # Show first 3\n",
    "        \n",
    "        # Show preview (first 300 chars)\n",
    "        preview = serialized[:300] + \"...\" if len(serialized) > 300 else serialized\n",
    "        print(preview)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 8: Complete Extraction Pipeline\n",
    "\n",
    "Let's build a complete pipeline: **Entities \u2192 Relations \u2192 Triplets**\n",
    "\n",
    "This demonstrates the full workflow for knowledge graph construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_knowledge(text):\n",
    "    \"\"\"\n",
    "    Complete knowledge extraction pipeline.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        \n",
    "    Returns:\n",
    "        dict: Extracted entities, relations, and triplets\n",
    "    \"\"\"\n",
    "    # Step 1: Extract entities\n",
    "    entities = ner_extractor.extract(text)\n",
    "    \n",
    "    # Step 2: Extract relations\n",
    "    relations = relation_extractor.extract(text, entities)\n",
    "    \n",
    "    # Step 3: Extract triplets\n",
    "    triplets = triplet_extractor.extract_triplets(text, entities=entities, relationships=relations)\n",
    "    \n",
    "    # Step 4: Validate triplets\n",
    "    valid_triplets = validator.validate_triplets(triplets)\n",
    "    \n",
    "    return {\n",
    "        'entities': entities,\n",
    "        'relations': relations,\n",
    "        'triplets': valid_triplets\n",
    "    }\n",
    "\n",
    "# Sample knowledge-rich text\n",
    "knowledge_text = \"\"\"\n",
    "Tesla Inc. was founded by Elon Musk, JB Straubel, Martin Eberhard, Marc Tarpenning, \n",
    "and Ian Wright in 2003. The company is headquartered in Austin, Texas. Tesla produces \n",
    "electric vehicles including the Model S, Model 3, Model X, and Model Y. Elon Musk serves \n",
    "as CEO and has been instrumental in the company's growth.\n",
    "\"\"\"\n",
    "\n",
    "print(\" Complete Extraction Pipeline:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Run pipeline\n",
    "result = extract_knowledge(knowledge_text)\n",
    "\n",
    "print(f\"\\n Extraction Results:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Entities extracted: {len(result['entities'])}\")\n",
    "print(f\"Relations extracted: {len(result['relations'])}\")\n",
    "print(f\"Triplets extracted: {len(result['triplets'])}\")\n",
    "\n",
    "print(f\"\\n Sample Triplets:\")\n",
    "for i, triplet in enumerate(result['triplets'][:5], 1):\n",
    "    subject = triplet.get('subject', '') if isinstance(triplet, dict) else triplet.subject\n",
    "    predicate = triplet.get('predicate', '') if isinstance(triplet, dict) else triplet.predicate\n",
    "    obj = triplet.get('object', '') if isinstance(triplet, dict) else triplet.object\n",
    "    print(f\"  {i}. ({subject}, {predicate}, {obj})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 9: Best Practices & Tips\n",
    "\n",
    "###  Choosing the Right Method\n",
    "\n",
    "1. **Start with pattern-based** for common relations\n",
    "2. **Use dependency parsing** for grammatical accuracy\n",
    "3. **Try co-occurrence** for exploratory analysis\n",
    "4. **Consider LLM** for complex, domain-specific relations\n",
    "\n",
    "### \ufe0f Optimizing Extraction\n",
    "\n",
    "- **Set confidence thresholds** (0.6-0.7 for production)\n",
    "- **Specify relation_types** to focus extraction\n",
    "- **Adjust max_distance** based on text structure\n",
    "- **Validate triplets** before using in knowledge graphs\n",
    "\n",
    "###  Common Pitfalls to Avoid\n",
    "\n",
    "-  **Don't** skip entity extraction (relations need entities)\n",
    "-  **Don't** use very low confidence thresholds\n",
    "-  **Don't** ignore relation validation\n",
    "-  **Don't** forget to serialize triplets for storage\n",
    "\n",
    "###  When to Use Each Component\n",
    "\n",
    "| Use Case | Recommended Component |\n",
    "|----------|----------------------|\n",
    "| Find entity connections | `RelationExtractor` |\n",
    "| Build knowledge graphs | `TripletExtractor` |\n",
    "| Quality assurance | `TripletValidator` |\n",
    "| Export to RDF | `RDFSerializer` |\n",
    "| Assess extraction quality | `TripletQualityChecker` |\n",
    "\n",
    "###  Performance Tips\n",
    "\n",
    "1. **Extract entities once**, reuse for relations and triplets\n",
    "2. **Batch process** multiple documents together\n",
    "3. **Cache extractors** instead of recreating\n",
    "4. **Filter early** with confidence thresholds\n",
    "5. **Validate incrementally** rather than all at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "In this notebook, you've learned how to:\n",
    "\n",
    " **Extract relationships** using `RelationExtractor`  \n",
    " **Compare extraction methods** (pattern, dependency, co-occurrence, HuggingFace, LLM)  \n",
    " **Configure extraction parameters** for optimal results  \n",
    " **Extract RDF triplets** with `TripletExtractor`  \n",
    " **Validate triplets** using `TripletValidator`  \n",
    " **Serialize to RDF formats** with `RDFSerializer`  \n",
    " **Assess quality** with `TripletQualityChecker`  \n",
    " **Build complete pipelines** from entities to triplets  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Relations connect entities**: They form the backbone of knowledge graphs\n",
    "2. **Multiple methods available**: Choose based on accuracy vs speed needs\n",
    "3. **Configuration is powerful**: Tune parameters for your domain\n",
    "4. **Triplets are standardized**: Use RDF for interoperability\n",
    "5. **Validation is essential**: Ensure quality before using triplets\n",
    "6. **Pipelines are efficient**: Extract entities \u2192 relations \u2192 triplets in sequence\n",
    "\n",
    "### Next Steps\n",
    "\n",
    " **Next Notebook**: [07_Building_Knowledge_Graphs.ipynb](./07_Building_Knowledge_Graphs.ipynb)  \n",
    "Learn how to build complete knowledge graphs from your extracted triplets!\n",
    "\n",
    " **Further Reading**:\n",
    "- [Semantic Extract API Reference](https://semantica.readthedocs.io/reference/semantic_extract/)\n",
    "- [Knowledge Graph Module](https://semantica.readthedocs.io/reference/kg/)\n",
    "- [Advanced Graph Analytics](../advanced/02_Advanced_Graph_Analytics.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or Issues?** Check out our [GitHub repository](https://github.com/Hawksight-AI/semantica) or [documentation](https://semantica.readthedocs.io)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}